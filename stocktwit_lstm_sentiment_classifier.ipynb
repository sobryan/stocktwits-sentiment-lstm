{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "stocktwit_lstm_sentiment_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-Kemj3z5Awl"
      },
      "source": [
        "# LSTM Sentiment Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xxADu2B5Aws"
      },
      "source": [
        "In this notebook, we use an LSTM layer to classify stocktwit messages by their sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuGz6HUf5Awu"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/conv_lstm_stack_sentiment_classifier.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S60OQQho5Awx"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj7i7gnS5Awz"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, Activation\n",
        "from keras.layers.wrappers import Bidirectional \n",
        "from keras.layers import Conv1D, MaxPooling1D \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUFpQsU0OdIW"
      },
      "source": [
        "import pandas as pd # provide sql-like data manipulation tools. very handy.\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np # high dimensional vector computing library.\n",
        "from copy import deepcopy\n",
        "from string import punctuation\n",
        "from random import shuffle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsj33uRa5Aw4"
      },
      "source": [
        "#### Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ8CxyuI5Aw6"
      },
      "source": [
        "# output directory name:\n",
        "output_dir = 'model_output/sentimentLSTM'\n",
        "\n",
        "# training:\n",
        "epochs = 4\n",
        "batch_size = 32\n",
        "\n",
        "# vector-space embedding: \n",
        "n_dim = 200\n",
        "n_unique_words = 10000 \n",
        "\n",
        "# max length of stocktwits\n",
        "max_review_length = 1000 \n",
        "pad_type = trunc_type = 'pre'\n",
        "drop_embed = 0.2 \n",
        "\n",
        "# convolutional layer architecture:\n",
        "n_conv = 64  \n",
        "k_conv = 3 \n",
        "mp_size = 4\n",
        "\n",
        "# LSTM layer architecture:\n",
        "# n_lstm = 64 \n",
        "# drop_lstm = 0.2\n",
        "\n",
        "# LSTM layer architecture:\n",
        "n_lstm = 256\n",
        "drop_lstm = 0.2\n",
        "\n",
        "# dense layer architecture: \n",
        "# n_dense = 256\n",
        "# dropout = 0.2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohqg-_E_5Aw7"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGht8jjyPPHt",
        "outputId": "0754cfd4-b750-4c5c-b44f-28fecb848a17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnWOXGvlNnF2"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/uiowa-central/BAIS9010/personal-notebooks/data/TSLA-output-new.csv')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r9N6g80OJO1",
        "outputId": "f4c7cdf9-4719-4039-e31d-b95928fd1d11"
      },
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8fDLHZ9Mtx8"
      },
      "source": [
        "def clean_message(twit):\n",
        "  try:\n",
        "    tokens = twit.split()\n",
        "    tokens = filter(lambda t: not t.startswith('@'), tokens)\n",
        "    tokens = filter(lambda t: not t.startswith('#'), tokens)\n",
        "    tokens = filter(lambda t: not t.startswith('http'), tokens)\n",
        "    tokens = filter(lambda t: not t.startswith('$'), tokens)\n",
        "    tokens = filter(lambda t: not '.com' in t, tokens)\n",
        "    tokens = filter(lambda t: not '.net' in t, tokens)\n",
        "    tokens = filter(lambda t: not '.biz' in t, tokens)\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    tokens = word_tokenize(' '.join(tokens))\n",
        "    # remove punctuation from each word\n",
        "    table = str.maketrans('','',string.punctuation)\n",
        "    stripped = [w.translate(table) for w in tokens]\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    words = [word for word in stripped if word.isalpha()]\n",
        "    # make unicode\n",
        "    # words = [str(w,'utf-8') for w in words]\n",
        "\n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    return words\n",
        "  except:\n",
        "    return 'NC'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1k-TRF9OdOt"
      },
      "source": [
        "data['tokens'] = data.message.map(clean_message)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqq4P6COeol"
      },
      "source": [
        "# remove rows with empty lists\n",
        "data = data[data.tokens.astype(bool)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UpxXxqSfmRT",
        "outputId": "e845c81d-7521-4416-b721-ad2944744f4a"
      },
      "source": [
        "data.describe"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of      symbol  ...                                             tokens\n",
              "0      TSLA  ...  [p, committee, ashamed, allowing, p, funds, ma...\n",
              "1      TSLA  ...  [reached, place, new, followers, last, word, l...\n",
              "2      TSLA  ...  [fsd, subscription, bigger, netflix, college, ...\n",
              "3      TSLA  ...                                              [nio]\n",
              "4      TSLA  ...                        [honestly, concerning, ocx]\n",
              "...     ...  ...                                                ...\n",
              "4853   TSLA  ...                                               [go]\n",
              "4855   TSLA  ...               [getting, puts, market, close, load]\n",
              "4856   TSLA  ...                                             [dump]\n",
              "4857   TSLA  ...  [puts, look, like, bulls, doubled, parasite, p...\n",
              "4858   TSLA  ...                       [lol, bulls, still, posting]\n",
              "\n",
              "[4491 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKDgSiqM4e2S",
        "outputId": "a96588f5-8a7d-434f-b70c-77c6bf8ee327"
      },
      "source": [
        "import gensim\n",
        "import gensim.models\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "189UHTbSt547"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOq0KpjWt61K"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(np.array(data.tokens), np.array(data.sentiment), test_size=0.2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpx0-YQnwAqc",
        "outputId": "72cc7304-61ea-471e-a466-8ff862151962"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3592,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZhWVz0CwH3M",
        "outputId": "e8daf8d8-ac12-485a-f904-f22832407cb5"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3592,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxvHs04p2ZS4"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from tensorflow.python.keras.preprocessing import text"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfCsS0oh2Y_O",
        "outputId": "8613ffbb-d98e-4909-a656-3d06911b83f9"
      },
      "source": [
        "# alternative to word2vec process \n",
        "# derived from: https://developers.google.com/machine-learning/guides/text-classification/step-3#sequence_vectors_option_b\n",
        "\n",
        "# Vectorization parameters\n",
        "# Limit on the number of features. We use the top 20K features.\n",
        "TOP_K = 20000\n",
        "\n",
        "# Limit on the length of text sequences. Sequences longer than this\n",
        "# will be truncated.\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "\n",
        "# Create vocabulary with training texts.\n",
        "tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "# Vectorize training and validation texts.\n",
        "x_train2 = tokenizer.texts_to_sequences(x_train)\n",
        "x_val2 = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Get max sequence length.\n",
        "max_length = len(max(x_train2, key=len))\n",
        "if max_length > MAX_SEQUENCE_LENGTH:\n",
        "  max_length = MAX_SEQUENCE_LENGTH\n",
        "\n",
        "    # Fix sequence length to max value. Sequences shorter than the length are\n",
        "    # padded in the beginning and sequences longer are truncated\n",
        "    # at the beginning.\n",
        "x_train2 = sequence.pad_sequences(x_train2, maxlen=max_length)\n",
        "x_val2 = sequence.pad_sequences(x_val2, maxlen=max_length)\n",
        "\n",
        "x_train2\n",
        "x_val2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   57,  769,  216],\n",
              "       [   0,    0,    0, ...,   88,  449, 1291],\n",
              "       [   0,    0,    0, ...,    0,    0,  294],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    0,    0,    9],\n",
              "       [   0,    0,    0, ...,    0,    0, 2935],\n",
              "       [   0,    0,    0, ...,   24,   11,   26]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sfHuySVL8Hd",
        "outputId": "b2ab7f91-ba1f-42bb-e52f-d70c78a2b596"
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3uWAMwDQOtO",
        "outputId": "672ad584-7f19-474b-e246-d7180132119d"
      },
      "source": [
        "# ended up not using\n",
        "\n",
        "# train word2vec model\n",
        "twit_word_model = gensim.models.Word2Vec(sentences=data.tokens, size=n_dim, window=5,workers=8,min_count=1, iter=50)\n",
        "pretrained_weights = twit_word_model.wv.syn0\n",
        "vocab_size, embedding_size = pretrained_weights.shape\n",
        "# twit_word2vec.build_vocab([x.words for x in tqdm(x_train)])\n",
        "# tweet_w2v = Word2Vec(size=n_dim, min_count=10)\n",
        "# tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
        "# tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=x_train.count, epochs=2)\n",
        "# print('count %s', x_train.count)\n",
        "# twit_word2vec.train([x for x in tqdm(x_train)], total_examples=len(x_train), epochs=50)\n",
        "\n"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udX1GEfo-6SE"
      },
      "source": [
        "# not used\n",
        "\n",
        "def word2index(word):\n",
        "  return twit_word_model.wv.vocab[word].index\n",
        "\n",
        "def index2word(idx):\n",
        "  return twit_word_model.wv.index2word[idx]"
      ],
      "execution_count": 507,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNKrO7sWBtt5"
      },
      "source": [
        "# Model using a sigmoid output with binary crossentropy\n",
        "\n",
        "# x_train2\n",
        "# x_val2\n",
        "model_sigmoid = Sequential()\n",
        "model_sigmoid.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights]))\n",
        "model_sigmoid.add(LSTM(units=embedding_size))\n",
        "model_sigmoid.add(Dense(units=vocab_size))\n",
        "model_sigmoid.add(Dense(1,activation='sigmoid'))\n",
        "model_sigmoid.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hOo7rDyCKG7",
        "outputId": "9dbec6c3-5107-460e-d412-1ddc866f6cb4"
      },
      "source": [
        "model_sigmoid.fit(x_train2, y_train, epochs=100, batch_size=128, verbose=2)\n"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 - 3s - loss: 0.5677 - accuracy: 0.7481\n",
            "Epoch 2/100\n",
            "29/29 - 1s - loss: 0.5217 - accuracy: 0.7636\n",
            "Epoch 3/100\n",
            "29/29 - 1s - loss: 0.4490 - accuracy: 0.7876\n",
            "Epoch 4/100\n",
            "29/29 - 1s - loss: 0.3203 - accuracy: 0.8669\n",
            "Epoch 5/100\n",
            "29/29 - 1s - loss: 0.2150 - accuracy: 0.9109\n",
            "Epoch 6/100\n",
            "29/29 - 1s - loss: 0.1816 - accuracy: 0.9298\n",
            "Epoch 7/100\n",
            "29/29 - 1s - loss: 0.0994 - accuracy: 0.9613\n",
            "Epoch 8/100\n",
            "29/29 - 1s - loss: 0.0775 - accuracy: 0.9694\n",
            "Epoch 9/100\n",
            "29/29 - 1s - loss: 0.0742 - accuracy: 0.9722\n",
            "Epoch 10/100\n",
            "29/29 - 1s - loss: 0.0552 - accuracy: 0.9791\n",
            "Epoch 11/100\n",
            "29/29 - 1s - loss: 0.0547 - accuracy: 0.9763\n",
            "Epoch 12/100\n",
            "29/29 - 1s - loss: 0.0414 - accuracy: 0.9844\n",
            "Epoch 13/100\n",
            "29/29 - 1s - loss: 0.0348 - accuracy: 0.9880\n",
            "Epoch 14/100\n",
            "29/29 - 1s - loss: 0.0427 - accuracy: 0.9841\n",
            "Epoch 15/100\n",
            "29/29 - 1s - loss: 0.0322 - accuracy: 0.9872\n",
            "Epoch 16/100\n",
            "29/29 - 1s - loss: 0.0422 - accuracy: 0.9839\n",
            "Epoch 17/100\n",
            "29/29 - 1s - loss: 0.0392 - accuracy: 0.9844\n",
            "Epoch 18/100\n",
            "29/29 - 1s - loss: 0.0284 - accuracy: 0.9889\n",
            "Epoch 19/100\n",
            "29/29 - 1s - loss: 0.0279 - accuracy: 0.9889\n",
            "Epoch 20/100\n",
            "29/29 - 1s - loss: 0.0251 - accuracy: 0.9911\n",
            "Epoch 21/100\n",
            "29/29 - 1s - loss: 0.0238 - accuracy: 0.9914\n",
            "Epoch 22/100\n",
            "29/29 - 1s - loss: 0.0273 - accuracy: 0.9883\n",
            "Epoch 23/100\n",
            "29/29 - 1s - loss: 0.0231 - accuracy: 0.9905\n",
            "Epoch 24/100\n",
            "29/29 - 1s - loss: 0.0224 - accuracy: 0.9922\n",
            "Epoch 25/100\n",
            "29/29 - 1s - loss: 0.0254 - accuracy: 0.9878\n",
            "Epoch 26/100\n",
            "29/29 - 1s - loss: 0.0217 - accuracy: 0.9911\n",
            "Epoch 27/100\n",
            "29/29 - 1s - loss: 0.0197 - accuracy: 0.9911\n",
            "Epoch 28/100\n",
            "29/29 - 1s - loss: 0.0203 - accuracy: 0.9911\n",
            "Epoch 29/100\n",
            "29/29 - 1s - loss: 0.0185 - accuracy: 0.9916\n",
            "Epoch 30/100\n",
            "29/29 - 1s - loss: 0.0193 - accuracy: 0.9908\n",
            "Epoch 31/100\n",
            "29/29 - 1s - loss: 0.0192 - accuracy: 0.9908\n",
            "Epoch 32/100\n",
            "29/29 - 1s - loss: 0.0228 - accuracy: 0.9905\n",
            "Epoch 33/100\n",
            "29/29 - 1s - loss: 0.0225 - accuracy: 0.9894\n",
            "Epoch 34/100\n",
            "29/29 - 1s - loss: 0.0270 - accuracy: 0.9891\n",
            "Epoch 35/100\n",
            "29/29 - 1s - loss: 0.0389 - accuracy: 0.9847\n",
            "Epoch 36/100\n",
            "29/29 - 1s - loss: 0.0255 - accuracy: 0.9905\n",
            "Epoch 37/100\n",
            "29/29 - 1s - loss: 0.0205 - accuracy: 0.9905\n",
            "Epoch 38/100\n",
            "29/29 - 1s - loss: 0.0186 - accuracy: 0.9911\n",
            "Epoch 39/100\n",
            "29/29 - 1s - loss: 0.0182 - accuracy: 0.9914\n",
            "Epoch 40/100\n",
            "29/29 - 1s - loss: 0.0229 - accuracy: 0.9900\n",
            "Epoch 41/100\n",
            "29/29 - 1s - loss: 0.0213 - accuracy: 0.9925\n",
            "Epoch 42/100\n",
            "29/29 - 1s - loss: 0.0178 - accuracy: 0.9914\n",
            "Epoch 43/100\n",
            "29/29 - 1s - loss: 0.0163 - accuracy: 0.9916\n",
            "Epoch 44/100\n",
            "29/29 - 1s - loss: 0.0186 - accuracy: 0.9911\n",
            "Epoch 45/100\n",
            "29/29 - 1s - loss: 0.0188 - accuracy: 0.9908\n",
            "Epoch 46/100\n",
            "29/29 - 1s - loss: 0.0172 - accuracy: 0.9922\n",
            "Epoch 47/100\n",
            "29/29 - 1s - loss: 0.0170 - accuracy: 0.9922\n",
            "Epoch 48/100\n",
            "29/29 - 1s - loss: 0.0169 - accuracy: 0.9908\n",
            "Epoch 49/100\n",
            "29/29 - 1s - loss: 0.0160 - accuracy: 0.9916\n",
            "Epoch 50/100\n",
            "29/29 - 1s - loss: 0.0181 - accuracy: 0.9911\n",
            "Epoch 51/100\n",
            "29/29 - 1s - loss: 0.0183 - accuracy: 0.9925\n",
            "Epoch 52/100\n",
            "29/29 - 1s - loss: 0.0175 - accuracy: 0.9922\n",
            "Epoch 53/100\n",
            "29/29 - 1s - loss: 0.0174 - accuracy: 0.9916\n",
            "Epoch 54/100\n",
            "29/29 - 1s - loss: 0.0191 - accuracy: 0.9916\n",
            "Epoch 55/100\n",
            "29/29 - 1s - loss: 0.0166 - accuracy: 0.9925\n",
            "Epoch 56/100\n",
            "29/29 - 1s - loss: 0.0162 - accuracy: 0.9916\n",
            "Epoch 57/100\n",
            "29/29 - 1s - loss: 0.0160 - accuracy: 0.9911\n",
            "Epoch 58/100\n",
            "29/29 - 1s - loss: 0.0167 - accuracy: 0.9916\n",
            "Epoch 59/100\n",
            "29/29 - 1s - loss: 0.0159 - accuracy: 0.9916\n",
            "Epoch 60/100\n",
            "29/29 - 1s - loss: 0.0159 - accuracy: 0.9916\n",
            "Epoch 61/100\n",
            "29/29 - 1s - loss: 0.0158 - accuracy: 0.9922\n",
            "Epoch 62/100\n",
            "29/29 - 1s - loss: 0.0336 - accuracy: 0.9878\n",
            "Epoch 63/100\n",
            "29/29 - 1s - loss: 0.0210 - accuracy: 0.9908\n",
            "Epoch 64/100\n",
            "29/29 - 1s - loss: 0.0179 - accuracy: 0.9908\n",
            "Epoch 65/100\n",
            "29/29 - 1s - loss: 0.0234 - accuracy: 0.9914\n",
            "Epoch 66/100\n",
            "29/29 - 1s - loss: 0.0216 - accuracy: 0.9916\n",
            "Epoch 67/100\n",
            "29/29 - 1s - loss: 0.0205 - accuracy: 0.9914\n",
            "Epoch 68/100\n",
            "29/29 - 1s - loss: 0.0220 - accuracy: 0.9908\n",
            "Epoch 69/100\n",
            "29/29 - 1s - loss: 0.0174 - accuracy: 0.9911\n",
            "Epoch 70/100\n",
            "29/29 - 1s - loss: 0.0169 - accuracy: 0.9916\n",
            "Epoch 71/100\n",
            "29/29 - 1s - loss: 0.0164 - accuracy: 0.9922\n",
            "Epoch 72/100\n",
            "29/29 - 1s - loss: 0.0160 - accuracy: 0.9914\n",
            "Epoch 73/100\n",
            "29/29 - 1s - loss: 0.0166 - accuracy: 0.9908\n",
            "Epoch 74/100\n",
            "29/29 - 1s - loss: 0.0154 - accuracy: 0.9919\n",
            "Epoch 75/100\n",
            "29/29 - 1s - loss: 0.0180 - accuracy: 0.9922\n",
            "Epoch 76/100\n",
            "29/29 - 1s - loss: 0.0173 - accuracy: 0.9911\n",
            "Epoch 77/100\n",
            "29/29 - 1s - loss: 0.0157 - accuracy: 0.9919\n",
            "Epoch 78/100\n",
            "29/29 - 1s - loss: 0.0157 - accuracy: 0.9916\n",
            "Epoch 79/100\n",
            "29/29 - 1s - loss: 0.0163 - accuracy: 0.9925\n",
            "Epoch 80/100\n",
            "29/29 - 1s - loss: 0.0150 - accuracy: 0.9919\n",
            "Epoch 81/100\n",
            "29/29 - 1s - loss: 0.0161 - accuracy: 0.9914\n",
            "Epoch 82/100\n",
            "29/29 - 1s - loss: 0.0155 - accuracy: 0.9919\n",
            "Epoch 83/100\n",
            "29/29 - 1s - loss: 0.0154 - accuracy: 0.9930\n",
            "Epoch 84/100\n",
            "29/29 - 1s - loss: 0.0150 - accuracy: 0.9928\n",
            "Epoch 85/100\n",
            "29/29 - 1s - loss: 0.0158 - accuracy: 0.9930\n",
            "Epoch 86/100\n",
            "29/29 - 1s - loss: 0.0160 - accuracy: 0.9916\n",
            "Epoch 87/100\n",
            "29/29 - 1s - loss: 0.0152 - accuracy: 0.9919\n",
            "Epoch 88/100\n",
            "29/29 - 1s - loss: 0.0151 - accuracy: 0.9916\n",
            "Epoch 89/100\n",
            "29/29 - 1s - loss: 0.0153 - accuracy: 0.9933\n",
            "Epoch 90/100\n",
            "29/29 - 1s - loss: 0.0153 - accuracy: 0.9928\n",
            "Epoch 91/100\n",
            "29/29 - 1s - loss: 0.0147 - accuracy: 0.9919\n",
            "Epoch 92/100\n",
            "29/29 - 1s - loss: 0.0150 - accuracy: 0.9919\n",
            "Epoch 93/100\n",
            "29/29 - 1s - loss: 0.0156 - accuracy: 0.9911\n",
            "Epoch 94/100\n",
            "29/29 - 1s - loss: 0.0153 - accuracy: 0.9919\n",
            "Epoch 95/100\n",
            "29/29 - 1s - loss: 0.0153 - accuracy: 0.9919\n",
            "Epoch 96/100\n",
            "29/29 - 1s - loss: 0.0147 - accuracy: 0.9919\n",
            "Epoch 97/100\n",
            "29/29 - 1s - loss: 0.0149 - accuracy: 0.9911\n",
            "Epoch 98/100\n",
            "29/29 - 1s - loss: 0.0151 - accuracy: 0.9911\n",
            "Epoch 99/100\n",
            "29/29 - 1s - loss: 0.0150 - accuracy: 0.9922\n",
            "Epoch 100/100\n",
            "29/29 - 1s - loss: 0.0142 - accuracy: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefc632f490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kl41RSS7a5C",
        "outputId": "8bc59b6b-07dc-4f18-f41e-a16982080d50"
      },
      "source": [
        "# not used\n",
        "\n",
        "\n",
        "\n",
        "# print('\\nPreparing the data for LSTM...')\n",
        "# \n",
        "# test_x_orig = x_test\n",
        "# test_y_orig = y_test\n",
        "# \n",
        "# test_x = np.zeros([len(test_x_orig), 10000], dtype=np.int32)\n",
        "# test_y = np.zeros([len(test_x_orig)], dtype=np.int32)\n",
        "# for i, sentence in enumerate(test_x_orig):\n",
        "#   for t, word in enumerate(sentence[:-1]):\n",
        "#     test_x[i, t] = word2index(word)\n",
        "#   test_y[i] = word2index(sentence[-1])\n",
        "# print('test_x shape:', test_x.shape)\n",
        "# print('test_y shape:', test_y.shape)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing the data for LSTM...\n",
            "test_x shape: (335, 10000)\n",
            "test_y shape: (335,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saHUEgIqCaUa",
        "outputId": "39e9cc3d-0688-4909-fcce-6e2b46a17b07"
      },
      "source": [
        "# evaluate the score\n",
        "score = model_sigmoid.evaluate(x_val2, y_test, batch_size=128, verbose=2)\n"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 - 1s - loss: 2.3353 - accuracy: 0.7820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp98BJVq73DT",
        "outputId": "7aeaf055-3c6a-40f9-9d1e-6c016c6972cc"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3353097438812256, 0.7819799780845642]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llsHNiEa55Wl"
      },
      "source": [
        "model_softmax = Sequential()\n",
        "model_softmax.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights]))\n",
        "model_softmax.add(LSTM(units=embedding_size))\n",
        "model_softmax.add(Dense(units=vocab_size))\n",
        "model_softmax.add(Activation('softmax'))\n",
        "# model.add(Dense(1,activation='sigmoid'))\n",
        "model_softmax.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-kxjHRR5-o9",
        "outputId": "e41e7362-0762-46a1-d06f-8c7cef30f458"
      },
      "source": [
        "model_softmax.fit(x_train2, y_train, epochs=100, batch_size=128, verbose=2)\n"
      ],
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 - 2s - loss: 4.0463 - accuracy: 0.7241\n",
            "Epoch 2/100\n",
            "29/29 - 1s - loss: 0.5647 - accuracy: 0.7556\n",
            "Epoch 3/100\n",
            "29/29 - 1s - loss: 0.5584 - accuracy: 0.7556\n",
            "Epoch 4/100\n",
            "29/29 - 1s - loss: 0.5593 - accuracy: 0.7556\n",
            "Epoch 5/100\n",
            "29/29 - 1s - loss: 0.5596 - accuracy: 0.7556\n",
            "Epoch 6/100\n",
            "29/29 - 1s - loss: 0.5586 - accuracy: 0.7556\n",
            "Epoch 7/100\n",
            "29/29 - 1s - loss: 0.5606 - accuracy: 0.7556\n",
            "Epoch 8/100\n",
            "29/29 - 1s - loss: 0.5596 - accuracy: 0.7556\n",
            "Epoch 9/100\n",
            "29/29 - 1s - loss: 0.5608 - accuracy: 0.7556\n",
            "Epoch 10/100\n",
            "29/29 - 1s - loss: 0.5580 - accuracy: 0.7556\n",
            "Epoch 11/100\n",
            "29/29 - 1s - loss: 0.5577 - accuracy: 0.7556\n",
            "Epoch 12/100\n",
            "29/29 - 1s - loss: 0.5602 - accuracy: 0.7556\n",
            "Epoch 13/100\n",
            "29/29 - 1s - loss: 0.5560 - accuracy: 0.7556\n",
            "Epoch 14/100\n",
            "29/29 - 1s - loss: 0.5561 - accuracy: 0.7556\n",
            "Epoch 15/100\n",
            "29/29 - 1s - loss: 0.5537 - accuracy: 0.7556\n",
            "Epoch 16/100\n",
            "29/29 - 1s - loss: 0.5506 - accuracy: 0.7556\n",
            "Epoch 17/100\n",
            "29/29 - 1s - loss: 0.5386 - accuracy: 0.7556\n",
            "Epoch 18/100\n",
            "29/29 - 1s - loss: 0.5276 - accuracy: 0.7556\n",
            "Epoch 19/100\n",
            "29/29 - 1s - loss: 0.4997 - accuracy: 0.7556\n",
            "Epoch 20/100\n",
            "29/29 - 1s - loss: 0.4749 - accuracy: 0.7556\n",
            "Epoch 21/100\n",
            "29/29 - 1s - loss: 0.4428 - accuracy: 0.7556\n",
            "Epoch 22/100\n",
            "29/29 - 1s - loss: 0.4128 - accuracy: 0.7876\n",
            "Epoch 23/100\n",
            "29/29 - 1s - loss: 0.3876 - accuracy: 0.8268\n",
            "Epoch 24/100\n",
            "29/29 - 1s - loss: 0.3647 - accuracy: 0.8558\n",
            "Epoch 25/100\n",
            "29/29 - 1s - loss: 0.3387 - accuracy: 0.8661\n",
            "Epoch 26/100\n",
            "29/29 - 1s - loss: 0.3197 - accuracy: 0.8744\n",
            "Epoch 27/100\n",
            "29/29 - 1s - loss: 0.2970 - accuracy: 0.8795\n",
            "Epoch 28/100\n",
            "29/29 - 1s - loss: 0.2680 - accuracy: 0.8970\n",
            "Epoch 29/100\n",
            "29/29 - 1s - loss: 0.2460 - accuracy: 0.9084\n",
            "Epoch 30/100\n",
            "29/29 - 1s - loss: 0.2244 - accuracy: 0.9159\n",
            "Epoch 31/100\n",
            "29/29 - 1s - loss: 0.2147 - accuracy: 0.9168\n",
            "Epoch 32/100\n",
            "29/29 - 1s - loss: 0.1997 - accuracy: 0.9257\n",
            "Epoch 33/100\n",
            "29/29 - 1s - loss: 0.1818 - accuracy: 0.9315\n",
            "Epoch 34/100\n",
            "29/29 - 1s - loss: 0.1739 - accuracy: 0.9337\n",
            "Epoch 35/100\n",
            "29/29 - 1s - loss: 0.1590 - accuracy: 0.9432\n",
            "Epoch 36/100\n",
            "29/29 - 1s - loss: 0.1470 - accuracy: 0.9504\n",
            "Epoch 37/100\n",
            "29/29 - 1s - loss: 0.1407 - accuracy: 0.9518\n",
            "Epoch 38/100\n",
            "29/29 - 1s - loss: 0.1323 - accuracy: 0.9552\n",
            "Epoch 39/100\n",
            "29/29 - 1s - loss: 0.1244 - accuracy: 0.9591\n",
            "Epoch 40/100\n",
            "29/29 - 1s - loss: 0.1163 - accuracy: 0.9610\n",
            "Epoch 41/100\n",
            "29/29 - 1s - loss: 0.1176 - accuracy: 0.9616\n",
            "Epoch 42/100\n",
            "29/29 - 1s - loss: 0.1097 - accuracy: 0.9652\n",
            "Epoch 43/100\n",
            "29/29 - 1s - loss: 0.1083 - accuracy: 0.9644\n",
            "Epoch 44/100\n",
            "29/29 - 1s - loss: 0.1028 - accuracy: 0.9641\n",
            "Epoch 45/100\n",
            "29/29 - 1s - loss: 0.1021 - accuracy: 0.9669\n",
            "Epoch 46/100\n",
            "29/29 - 1s - loss: 0.0960 - accuracy: 0.9685\n",
            "Epoch 47/100\n",
            "29/29 - 1s - loss: 0.0982 - accuracy: 0.9666\n",
            "Epoch 48/100\n",
            "29/29 - 1s - loss: 0.0923 - accuracy: 0.9710\n",
            "Epoch 49/100\n",
            "29/29 - 1s - loss: 0.0944 - accuracy: 0.9669\n",
            "Epoch 50/100\n",
            "29/29 - 1s - loss: 0.1038 - accuracy: 0.9621\n",
            "Epoch 51/100\n",
            "29/29 - 1s - loss: 0.0899 - accuracy: 0.9680\n",
            "Epoch 52/100\n",
            "29/29 - 1s - loss: 0.0837 - accuracy: 0.9710\n",
            "Epoch 53/100\n",
            "29/29 - 1s - loss: 0.0832 - accuracy: 0.9710\n",
            "Epoch 54/100\n",
            "29/29 - 1s - loss: 0.0803 - accuracy: 0.9727\n",
            "Epoch 55/100\n",
            "29/29 - 1s - loss: 0.0787 - accuracy: 0.9724\n",
            "Epoch 56/100\n",
            "29/29 - 1s - loss: 0.0788 - accuracy: 0.9724\n",
            "Epoch 57/100\n",
            "29/29 - 1s - loss: 0.0745 - accuracy: 0.9733\n",
            "Epoch 58/100\n",
            "29/29 - 1s - loss: 0.0756 - accuracy: 0.9744\n",
            "Epoch 59/100\n",
            "29/29 - 1s - loss: 0.0743 - accuracy: 0.9736\n",
            "Epoch 60/100\n",
            "29/29 - 1s - loss: 0.0773 - accuracy: 0.9716\n",
            "Epoch 61/100\n",
            "29/29 - 1s - loss: 0.0710 - accuracy: 0.9747\n",
            "Epoch 62/100\n",
            "29/29 - 1s - loss: 0.0703 - accuracy: 0.9758\n",
            "Epoch 63/100\n",
            "29/29 - 1s - loss: 0.0691 - accuracy: 0.9744\n",
            "Epoch 64/100\n",
            "29/29 - 1s - loss: 0.0676 - accuracy: 0.9761\n",
            "Epoch 65/100\n",
            "29/29 - 1s - loss: 0.0718 - accuracy: 0.9724\n",
            "Epoch 66/100\n",
            "29/29 - 1s - loss: 0.0684 - accuracy: 0.9752\n",
            "Epoch 67/100\n",
            "29/29 - 1s - loss: 0.0671 - accuracy: 0.9752\n",
            "Epoch 68/100\n",
            "29/29 - 1s - loss: 0.0659 - accuracy: 0.9758\n",
            "Epoch 69/100\n",
            "29/29 - 1s - loss: 0.0880 - accuracy: 0.9660\n",
            "Epoch 70/100\n",
            "29/29 - 1s - loss: 0.0660 - accuracy: 0.9752\n",
            "Epoch 71/100\n",
            "29/29 - 1s - loss: 0.0619 - accuracy: 0.9761\n",
            "Epoch 72/100\n",
            "29/29 - 1s - loss: 0.0719 - accuracy: 0.9688\n",
            "Epoch 73/100\n",
            "29/29 - 1s - loss: 0.0619 - accuracy: 0.9763\n",
            "Epoch 74/100\n",
            "29/29 - 1s - loss: 0.4300 - accuracy: 0.8513\n",
            "Epoch 75/100\n",
            "29/29 - 1s - loss: 0.5026 - accuracy: 0.7430\n",
            "Epoch 76/100\n",
            "29/29 - 1s - loss: 0.2606 - accuracy: 0.8736\n",
            "Epoch 77/100\n",
            "29/29 - 1s - loss: 0.1918 - accuracy: 0.9143\n",
            "Epoch 78/100\n",
            "29/29 - 1s - loss: 0.1530 - accuracy: 0.9360\n",
            "Epoch 79/100\n",
            "29/29 - 1s - loss: 0.1280 - accuracy: 0.9457\n",
            "Epoch 80/100\n",
            "29/29 - 1s - loss: 0.1124 - accuracy: 0.9543\n",
            "Epoch 81/100\n",
            "29/29 - 1s - loss: 0.0982 - accuracy: 0.9605\n",
            "Epoch 82/100\n",
            "29/29 - 1s - loss: 0.0875 - accuracy: 0.9669\n",
            "Epoch 83/100\n",
            "29/29 - 1s - loss: 0.0780 - accuracy: 0.9722\n",
            "Epoch 84/100\n",
            "29/29 - 1s - loss: 0.0743 - accuracy: 0.9705\n",
            "Epoch 85/100\n",
            "29/29 - 1s - loss: 0.0675 - accuracy: 0.9741\n",
            "Epoch 86/100\n",
            "29/29 - 1s - loss: 0.0655 - accuracy: 0.9763\n",
            "Epoch 87/100\n",
            "29/29 - 1s - loss: 0.0612 - accuracy: 0.9774\n",
            "Epoch 88/100\n",
            "29/29 - 1s - loss: 0.0590 - accuracy: 0.9772\n",
            "Epoch 89/100\n",
            "29/29 - 1s - loss: 0.0590 - accuracy: 0.9763\n",
            "Epoch 90/100\n",
            "29/29 - 1s - loss: 0.0570 - accuracy: 0.9783\n",
            "Epoch 91/100\n",
            "29/29 - 1s - loss: 0.0553 - accuracy: 0.9786\n",
            "Epoch 92/100\n",
            "29/29 - 1s - loss: 0.0548 - accuracy: 0.9788\n",
            "Epoch 93/100\n",
            "29/29 - 1s - loss: 0.0556 - accuracy: 0.9774\n",
            "Epoch 94/100\n",
            "29/29 - 1s - loss: 0.0544 - accuracy: 0.9813\n",
            "Epoch 95/100\n",
            "29/29 - 1s - loss: 0.0526 - accuracy: 0.9786\n",
            "Epoch 96/100\n",
            "29/29 - 1s - loss: 0.0516 - accuracy: 0.9766\n",
            "Epoch 97/100\n",
            "29/29 - 1s - loss: 0.0508 - accuracy: 0.9797\n",
            "Epoch 98/100\n",
            "29/29 - 1s - loss: 0.0525 - accuracy: 0.9783\n",
            "Epoch 99/100\n",
            "29/29 - 1s - loss: 0.0501 - accuracy: 0.9800\n",
            "Epoch 100/100\n",
            "29/29 - 1s - loss: 0.0497 - accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fefc675f650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBmoVoB76Mvt",
        "outputId": "f63f65de-01ac-47eb-e266-609810bb8eb3"
      },
      "source": [
        "# x_train2\n",
        "# x_val2\n",
        "# stopped here\n",
        "score = model_softmax.evaluate(x_val2, y_test, batch_size=128, verbose=2)\n"
      ],
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 - 1s - loss: 1.3163 - accuracy: 0.7508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR82kaPL6MnF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgaAZ4BD6Mat"
      },
      "source": [
        "###############\n",
        "#\n",
        "###############\n",
        "#       NOTE\n",
        "###############\n",
        "#\n",
        "# Everything below this cell was not used.  \n",
        "# I've kept the cells below to show the work/learning\n",
        "#\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ3cKx8C3s7K",
        "outputId": "5b36e175-1cfd-4ef5-9eb1-e0aad174c4ba"
      },
      "source": [
        "words = list(twit_word_model.wv.vocab)\n",
        "print('Vocab size: %d' % len(words))"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 4173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28NNLXpV5nlx",
        "outputId": "12ad7296-b572-4589-c194-70ef377ecdac"
      },
      "source": [
        "twit_word_model.wv.most_similar('elon')"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('musk', 0.9659481048583984),\n",
              " ('pumper', 0.9542982578277588),\n",
              " ('punch', 0.953281044960022),\n",
              " ('movies', 0.950433611869812),\n",
              " ('intention', 0.9500223398208618),\n",
              " ('loses', 0.9479587078094482),\n",
              " ('admitted', 0.9471251368522644),\n",
              " ('sog', 0.9409914612770081),\n",
              " ('enron', 0.9391332864761353),\n",
              " ('dogecoin', 0.9337623119354248)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLeRl7mb6GeD"
      },
      "source": [
        "twit_word_model.wv.most_similar_cosmul(positive=['gain'], negative=['loss'],topn=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KawsD5J4UTl7"
      },
      "source": [
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec \n",
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
        "TaggedDocument = gensim.models.doc2vec.TaggedDocument\n"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL986Qk_ULcL",
        "outputId": "d9188655-5132-46a6-9a5d-fa243d5a1f1e"
      },
      "source": [
        "def labelizeTweets(tweets, label_type):\n",
        "    labelized = []\n",
        "    for i,v in tqdm(enumerate(tweets)):\n",
        "        label = '%s_%s'%(label_type,i)\n",
        "        labelized.append(LabeledSentence(v, [label]))\n",
        "    return labelized\n",
        "\n",
        "x_train = labelizeTweets(x_train, 'TRAIN')\n",
        "x_test = labelizeTweets(x_test, 'TEST')"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
            "  \"\"\"\n",
            "1339it [00:00, 155305.93it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "335it [00:00, 181818.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB_jVM2cW7tw",
        "outputId": "4731aeea-fdb3-4239-f363-478186a4c701"
      },
      "source": [
        "def tagTwits(twits, tag_type):\n",
        "    tagged = []\n",
        "    for i,v in tqdm(enumerate(twits)):\n",
        "        tag = '%s_%s'%(tag_type,i)\n",
        "        tagged.append(TaggedDocument(v, [tag]))\n",
        "    return tagged\n",
        "\n",
        "x_train = tagTwits(x_train, 'TRAIN')\n",
        "x_test = tagTwits(x_test, 'TEST')"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1339it [00:00, 255803.83it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "335it [00:00, 560243.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haUCR2x7biJH",
        "outputId": "967ddc34-6b81-426e-83bf-ab42b8fe1075"
      },
      "source": [
        "twit_w2v = Word2Vec(size=n_dim, min_count=10)\n",
        "# twit_w2v.build_vocab([x.words for x in tqdm(x_train)])\n",
        "twit_w2v.build_vocab([x for x in tqdm(data.tokens)])\n",
        "twit_w2v.train([x for x in tqdm(data.tokens)],total_examples=len(data.tokens), epochs=50)"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1674/1674 [00:00<00:00, 1098102.11it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1674/1674 [00:00<00:00, 1051087.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(369983, 910750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VAgMCgpMSpK",
        "outputId": "126a3003-2260-4111-c3ef-47aafabcda04"
      },
      "source": [
        "twit_word_model.wv.vocab.keys()"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['p', 'committee', 'ashamed', 'allowing', 'funds', 'manipulate', 'tesla', 'stock', 'collaboration', 'money', 'managers', 'private', 'sources', 'reached', 'place', 'new', 'followers', 'last', 'word', 'liquidmetal', 'future', 'think', 'auto', 'first', 'mass', 'adopt', 'fsd', 'subscription', 'bigger', 'netflix', 'college', 'kids', 'spend', 'starbucks', 'per', 'month', 'cheap', 'though', 'would', 'price', 'least', 'starting', 'nio', 'honestly', 'concerning', 'ocx', 'x', 'king', 'china', 'turned', 'z', 'wall', 'street', 'love', 'stability', 'good', 'plus', 'growth', 'coming', 'gap', 'monday', 'time', 'buy', 'currently', 'huge', 'investor', 'cciv', 'lucid', 'motors', 'former', 'one', 'thing', 'learned', 'stocks', 'follow', 'closely', 'either', 'something', 'great', 'look', 'forward', 'merging', 'july', 'releasing', 'earnings', 'anticipation', 'official', 'merger', 'expected', 'share', 'prices', 'point', 'take', 'sometime', 'week', 'also', 'telling', 'popular', 'officially', 'cause', 'upwards', 'momentum', 'since', 'moving', 'neither', 'lagging', 'behind', 'expect', 'break', 'highs', 'top', 'trending', 'hours', 'sym', 'chtvol', 'chg', 'access', 'wider', 'trends', 'aapl', 'ultimate', 'luxury', 'loking', 'like', 'another', 'moonmonday', 'bears', 'watch', 'institutions', 'buying', 'tsla', 'years', 'using', 'car', 'without', 'ponzi', 'needs', 'hit', 'jukebox', 'meant', 'fonzi', 'futl', 'freaking', 'much', 'dd', 'mega', 'thread', 'verified', 'profile', 'connections', 'active', 'cbd', 'companies', 'ceo', 'cameron', 'cox', 'wife', 'working', 'market', 'cap', 'rumors', 'incoming', 'website', 'soon', 'owns', 'acres', 'grants', 'pass', 'wolf', 'creek', 'oregon', 'amps', 'electric', 'inc', 'building', 'vertically', 'control', 'quality', 'keep', 'profits', 'apotheca', 'biosciences', 'cannabinoid', 'pharma', 'bitcoinlabs', 'sold', 'acquisitions', 'made', 'complete', 'vertical', 'goal', 'filed', 'current', 'even', 'potential', 'reverse', 'going', 'explode', 'alert', 'really', 'want', 'make', 'profit', 'trading', 'amazingtradingroomstocks', 'sb', 'far', 'mean', 'elon', 'space', 'expanded', 'automobiles', 'internet', 'starlink', 'right', 'team', 'anything', 'possible', 'folks', 'video', 'games', 'virtual', 'reality', 'blockchain', 'nfts', 'battery', 'powertrain', 'potentially', 'artificial', 'intelligence', 'start', 'somewhere', 'us', 'sub', 'pennys', 'hold', 'britches', 'let', 'ride', 'simulated', 'dollar', 'calls', 'mondays', 'open', 'stockorbit', 'connection', 'obvious', 'sense', 'given', 'literally', 'better', 'making', 'cars', 'gold', 'dead', 'holy', 'crap', 'model', 'g', 'give', 'valuation', 'please', 'still', 'get', 'till', 'major', 'pr', 'pumpers', 'fool', 'minor', 'news', 'investors', 'need', 'substantial', 'partnership', 'reach', 'higher', 'sp', 'penny', 'product', 'prove', 'moon', 'mars', 'fly', 'next', 'months', 'bullish', 'pop', 'subscriptions', 'cash', 'cow', 'gm', 'sept', 'er', 'scary', 'ocgnx', 'called', 'pros', 'removed', 'feed', 'batch', 'sheep', 'find', 'way', 'see', 'smile', 'away', 'qna', 'happening', 'free', 'ocgnxio', 'tweet', 'today', 'change', 'ocgn', 'unusual', 'activity', 'delayed', 'exp', 'trade', 'volume', 'contracts', 'traded', 'type', 'split', 'options', 'try', 'mmat', 'spyx', 'hypothesis', 'crash', 'ocng', 'come', 'talk', 'roof', 'megapack', 'bulls', 'powerless', 'ape', 'always', 'feared', 'roblox', 'compromises', 'total', 'holdings', 'heavy', 'hitters', 'gains', 'feel', 'apex', 'names', 'runner', 'ten', 'opinion', 'others', 'big', 'run', 'dick', 'looks', 'baby', 'eraserhead', 'warming', 'picture', 'announce', 'doge', 'coins', 'holding', 'competition', 'short', 'finance', 'media', 'blowing', 'whistles', 'calm', 'know', 'sincerely', 'side', 'period', 'hear', 'say', 'plz', 'day', 'read', 'sweep', 'god', 'help', 'recalls', 'ford', 'handle', 'year', 'end', 'confident', 'clues', 'accepts', 'crypto', 'payments', 'yt', 'bye', 'shorts', 'go', 'join', 'discord', 'link', 'bio', 'block', 'prediction', 'announcement', 'play', 'shorted', 'kind', 'hugely', 'squeeze', 'construction', 'moto', 'governments', 'maybe', 'ready', 'guys', 'company', 'enjoy', 'surprise', 'lot', 'shares', 'left', 'xela', 'exela', 'technologies', 'put', 'simply', 'specializes', 'techenhanced', 'business', 'process', 'automation', 'bpa', 'impressive', 'track', 'record', 'experience', 'global', 'customers', 'across', 'industry', 'verticals', 'fortune', 'partnering', 'super', 'solid', 'techs', 'real', 'data', 'historical', 'graph', 'charts', 'land', 'anytime', 'regarding', 'healthcare', 'upcoming', 'catalysts', 'aside', 'shark', 'shorting', 'mm', 'manipulation', 'hailed', 'gamestop', 'gme', 'could', 'increase', 'exponentially', 'arena', 'clearly', 'remain', 'vigilant', 'scenario', 'dollars', 'stable', 'doubt', 'question', 'genuine', 'daily', 'updates', 'realtime', 'research', 'alerts', 'positions', 'problems', 'austria', 'plug', 'announced', 'earning', 'season', 'weeks', 'dont', 'happy', 'tank', 'delta', 'virus', 'infilation', 'old', 'smart', 'explanation', 'green', 'healty', 'pull', 'back', 'bs', 'bring', 'nikki', 'analysts', 'upgrades', 'pierre', 'ferragu', 'thank', 'tou', 'impact', 'ebit', 'multiple', 'yes', 'premium', 'second', 'hand', 'purchased', 'drive', 'signals', 'development', 'progresses', 'rocks', 'everyone', 'predictions', 'buyer', 'seller', 'sell', 'strangles', 'deltas', 'days', 'close', 'due', 'iv', 'crush', 'learn', 'priced', 'learning', 'trades', 'waiting', 'sure', 'stoolies', 'check', 'vs', 'best', 'vehicle', 'mergers', 'win', 'tickets', 'loaded', 'chance', 'beta', 'rollout', 'version', 'says', 'musk', 'might', 'cover', 'worthless', 'words', 'live', 'ifwhen', 'starts', 'amorphous', 'metal', 'memes', 'ev', 'federal', 'credit', 'bill', 'signed', 'never', 'unionized', 'maker', 'uaw', 'seriously', 'energy', 'coal', 'president', 'sentenced', 'prison', 'union', 'corruption', 'probe', 'ground', 'cross', 'eyes', 'makes', 'blurred', 'means', 'christ', 'addition', 'add', 'glasses', 'dog', 'call', 'coin', 'truth', 'represent', 'reflection', 'equivalent', 'smirking', 'rocket', 'launching', 'clouds', 'piercing', 'metals', 'achievable', 'meta', 'materials', 'created', 'labs', 'unbeknown', 'man', 'full', 'self', 'driving', 'available', 'cheapies', 'triple', 'sales', 'ranking', 'midtohighend', 'pure', 'vehicles', 'half', 'eow', 'criminal', 'playing', 'wording', 'rephrasing', 'appears', 'recall', 'failure', 'part', 'urges', 'chevy', 'bolt', 'owners', 'park', 'outside', 'fire', 'risk', 'clowns', 'regulators', 'refusing', 'protect', 'ppl', 'instead', 'urging', 'nanodimension', 'tonnes', 'enough', 'everything', 'happen', 'outline', 'invested', 'red', 'looking', 'entry', 'targets', 'posting', 'finally', 'mentions', 'happens', 'shit', 'hole', 'fuck', 'anyway', 'dvd', 'mention', 'fix', 'magical', 'ota', 'sorcery', 'hang', 'witch', 'long', 'term', 'crazy', 'thousands', 'hundreds', 'turn', 'millions', 'worry', 'power', 'house', 'dare', 'forget', 'experienced', 'individual', 'management', 'superb', 'trust', 'watchers', 'social', 'chatter', 'partnershipbuyout', 'rumor', 'deals', 'arrival', 'low', 'cost', 'commercial', 'manufacturing', 'game', 'changing', 'tech', 'concept', 'explains', 'well', 'giants', 'ups', 'uber', 'royalmail', 'leaseplan', 'hitachi', 'many', 'ordered', 'vans', 'worth', 'bn', 'ordering', 'van', 'couple', 'designing', 'hailing', 'lease', 'plan', 'recently', 'electrify', 'fleet', 'rated', 'startup', 'linkedin', 'uk', 'estimating', 'generate', 'revenue', 'ebitda', 'darn', 'hodlers', 'feeling', 'keeps', 'dipping', 'imagine', 'arec', 'patent', 'discusses', 'alloys', 'specifically', 'mentioning', 'suspect', 'use', 'along', 'ahead', 'competitors', 'technology', 'charger', 'network', 'released', 'ongoing', 'improvements', 'every', 'reward', 'investment', 'unbeatable', 'minimal', 'downside', 'survive', 'upside', 'numerous', 'cases', 'easily', 'trillion', 'addressable', 'markets', 'north', 'push', 'auntie', 'kathie', 'knows', 'known', 'party', 'glad', 'sized', 'kick', 'butt', 'straight', 'hell', 'energystoragenewsnewste', 'explosive', 'personally', 'figures', 'lows', 'indefinitely', 'people', 'realize', 'microvast', 'storage', 'packs', 'wu', 'providing', 'products', 'entire', 'seen', 'pic', 'familiar', 'onboard', 'someone', 'recent', 'evidence', 'articles', 'april', 'february', 'technical', 'analysis', 'washboardjim', 'charting', 'must', 'yep', 'comparing', 'beyond', 'advanced', 'automotive', 'ai', 'plans', 'alternative', 'solar', 'generated', 'expanding', 'achieving', 'milestones', 'superseding', 'automakers', 'blank', 'spac', 'fully', 'tested', 'road', 'cool', 'exterior', 'nothing', 'show', 'yet', 'little', 'cheerleaders', 'page', 'clue', 'spewing', 'conclusion', 'absolute', 'announces', 'orders', 'sunday', 'night', 'andor', 'buyout', 'contract', 'technicals', 'gon', 'na', 'mvis', 'newbies', 'brewing', 'ascent', 'times', 'results', 'contradict', 'assumptions', 'scientists', 'suggest', 'ways', 'engineering', 'electrodes', 'prevent', 'view', 'ic', 'chart', 'forming', 'beautiful', 'pattern', 'wait', 'confirmation', 'entering', 'understand', 'stay', 'upfront', 'goes', 'harder', 'launches', 'plant', 'powerwalls', 'california', 'grid', 'hello', 'peeps', 'hope', 'selfdriving', 'package', 'lead', 'remember', 'profitable', 'community', 'tuned', 'gain', 'hedge', 'decentralized', 'asset', 'protocol', 'allow', 'anyone', 'invest', 'decided', 'defi', 'driven', 'voting', 'platform', 'models', 'doubled', 'massively', 'failed', 'deliver', 'june', 'massive', 'support', 'life', 'opportunity', 'ever', 'discussion', 'hype', 'around', 'world', 'whenever', 'saying', 'negative', 'things', 'already', 'shoot', 'hahahahhaha', 'iykyk', 'ws', 'cramer', 'niche', 'automaker', 'nice', 'scale', 'nope', 'batteries', 'catching', 'dangerous', 'burn', 'lose', 'ap', 'causes', 'accidents', 'modelx', 'got', 'cr', 'rating', 'flop', 'produce', 'fraud', 'missing', 'delivery', 'collecting', 'bk', 'eminent', 'flow', 'exploded', 'pe', 'overvalued', 'kills', 'high', 'work', 'robotaxi', 'ouch', 'robot', 'missed', 'sorry', 'lost', 'inception', 'loss', 'stupidity', 'eat', 'heart', 'fans', 'fsdtedla', 'yowzas', 'cant', 'smoked', 'aabb', 'board', 'taking', 'executive', 'branch', 'fight', 'counterfeit', 'naked', 'carry', 'interest', 'unaccounted', 'covered', 'secgovoieacomplainthtml', 'pm', 'insurers', 'willing', 'discount', 'net', 'drivers', 'significantly', 'lower', 'ask', 'line', 'directions', 'rather', 'amc', 'two', 'additional', 'factories', 'operational', 'berlin', 'texas', 'factory', 'tbd', 'shortly', 'england', 'florida', 'success', 'fall', 'nasdaq', 'eoy', 'driver', 'safer', 'proven', 'statistics', 'feelings', 'giving', 'discounts', 'alarms', 'consists', 'distributed', 'systems', 'used', 'concert', 'provide', 'services', 'avoid', 'polluting', 'expensive', 'peaker', 'plants', 'perfect', 'hwy', 'occasion', 'commute', 'stressing', 'traffic', 'fatigue', 'owner', 'entered', 'saas', 'ontop', 'else', 'def', 'key', 'biggest', 'watching', 'recurring', 'shocking', 'mache', 'secondbest', 'munro', 'associates', 'torn', 'position', 'flying', 'care', 'n', 'analyst', 'thinks', 'designed', 'engineered', 'aliens', 'robots', 'maturing', 'matters', 'category', 'apple', 'profitability', 'margin', 'button', 'knew', 'weekend', 'whack', 'job', 'thinking', 'creating', 'church', 'trevor', 'milton', 'tax', 'exempt', 'members', 'deposit', 'winnings', 'pay', 'taxes', 'showing', 'states', 'regret', 'breakout', 'mode', 'sustained', 'partnerships', 'robotaxis', 'thats', 'insane', 'channel', 'pump', 'dump', 'financial', 'advice', 'stonk', 'guise', 'technokinga', 'taco', 'abou', 'billion', 'begin', 'able', 'initial', 'phase', 'production', 'unlike', 'fisker', 'lordstown', 'hyliion', 'workhorse', 'running', 'admitted', 'safe', 'bet', 'continually', 'subs', 'interesting', 'pt', 'increases', 'lol', 'theaters', 'partmershio', 'leading', 'theory', 'send', 'bought', 'taubman', 'employer', 'spg', 'jumped', 'purchase', 'deal', 'lmc', 'similar', 'sinario', 'nt', 'onto', 'forever', 'step', 'unlocking', 'wow', 'sea', 'yesterday', 'recon', 'bounced', 'strong', 'finish', 'referral', 'receive', 'supercharger', 'miles', 'earn', 'award', 'system', 'activation', 'purchasing', 'subscribing', 'panels', 'utility', 'computer', 'save', 'cali', 'catalyst', 'junk', 'brought', 'computers', 'wheels', 'fear', 'ones', 'seize', 'gift', 'lifetime', 'possibly', 'fair', 'guy', 'rumour', 'argo', 'talked', 'pw', 'liked', 'tweets', 'move', 'autonomy', 'achieved', 'hybrid', 'remote', 'command', 'center', 'infeasible', 'account', 'corner', 'manage', 'trained', 'detect', 'anomalous', 'efficiently', 'order', 'situations', 'request', 'controller', 'pullback', 'million', 'teslas', 'rate', 'annually', 'almost', 'annual', 'double', 'size', 'licensing', 'beginning', 'including', 'autosteer', 'city', 'streets', 'holds', 'kync', 'otc', 'began', 'launch', 'app', 'pre', 'mama', 'afraid', 'yoloing', 'index', 'action', 'strategy', 'thus', 'less', 'room', 'panic', 'selling', 'emotions', 'bidu', 'feb', 'international', 'event', 'within', 'chinese', 'happened', 'didi', 'unique', 'went', 'thru', 'ipo', 'warned', 'delay', 'government', 'benefit', 'map', 'service', 'advertising', 'beijing', 'olympics', 'holiday', 'december', 'bounce', 'targeted', 'unless', 'washington', 'tens', 'billions', 'american', 'tied', 'largest', 'population', 'closed', 'consensus', 'refreshed', 'may', 'eventually', 'outrite', 'decide', 'range', 'plaid', 'amazon', 'variant', 'jeff', 'bezos', 'trillionaire', 'likely', 'trip', 'dropped', 'loves', 'generating', 'features', 'acknowledges', 'cybertruck', 'design', 'congrats', 'followed', 'bringing', 'trump', 'white', 'runs', 'biden', 'paint', 'black', 'name', 'rule', 'possibility', 'swooping', 'advantage', 'cozier', 'trapped', 'waited', 'completely', 'release', 'subscribe', 'hour', 'summer', 'vacations', 'class', 'smarter', 'perfected', 'supervise', 'itintervene', 'raise', 'stfu', 'gamechanger', 'automobile', 'spaceballs', 'meme', 'professional', 'traders', 'limited', 'checkout', 'bitlyinvitesfreefornowon', 'opening', 'morning', 'ca', 'fucking', 'hoping', 'ah', 'fucked', 'dip', 'hiding', 'greedy', 'pigs', 'breaking', 'capability', 'contractorders', 'works', 'friday', 'paying', 'releases', 'longawaited', 'option', 'feature', 'details', 'rob', 'maurer', 'minutes', 'ago', 'offered', 'set', 'risen', 'costs', 'four', 'monthly', 'fee', 'newss', 'directly', 'bottom', 'ladies', 'gentlemen', 'offering', 'stuff', 'pops', 'install', 'converting', 'sunlight', 'clean', 'fraction', 'permitting', 'installation', 'site', 'carports', 'retard', 'tonight', 'true', 'horse', 'toupees', 'compare', 'usps', 'brainer', 'miss', 'boat', 'betting', 'spamware', 'lastly', 'contrast', 'closer', 'embryonic', 'stage', 'light', 'truck', 'headtohead', 'disappointed', 'prepared', 'honest', 'quickly', 'hard', 'shake', 'nonbelievers', 'nowhere', 'fomo', 'bankrupted', 'generation', 'documentary', 'pick', 'savior', 'scapegoat', 'wish', 'sway', 'decisions', 'camp', 'past', 'weekmonth', 'sucked', 'growing', 'monetization', 'partnershipandy', 'jassy', 'answer', 'highest', 'level', 'safety', 'certification', 'anybody', 'attain', 'yearsa', 'closest', 'boasts', 'autonomous', 'actually', 'near', 'getting', 'iso', 'asil', 'sooner', 'mighty', 'bend', 'knee', 'qnx', 'reason', 'discouraged', 'hodl', 'nearly', 'quarter', 'compared', 'report', 'experian', 'commanding', 'yahoo', 'trick', 'algos', 'root', 'insurance', 'whole', 'foods', 'thought', 'inbound', 'inclusion', 'tells', 'tale', 'trial', 'tool', 'printing', 'insider', 'info', 'iphones', 'picking', 'etfs', 'choose', 'robotic', 'apes', 'joined', 'gang', 'btc', 'instantly', 'potato', 'algo', 'llc', 'sets', 'target', 'source', 'deez', 'nutz', 'deliveries', 'seems', 'downs', 'hopefully', 'bull', 'sentiment', 'butnits', 'wild', 'partner', 'fools', 'latest', 'vid', 'sandy', 'co', 'mach', 'e', 'costly', 'jumble', 'piece', 'fund', 'insecure', 'retail', 'pos', 'broker', 'robinhood', 'moves', 'done', 'serves', 'trigger', 'fortunately', 'contemplate', 'sociopathic', 'tendencies', 'greed', 'eternity', 'arent', 'ends', 'isnt', 'assholes', 'streetand', 'pray', 'scrawny', 'bitches', 'fun', 'someday', 'havent', 'mind', 'paychecks', 'thanks', 'dummybears', 'btfd', 'bite', 'nails', 'outlined', 'buyers', 'guess', 'cares', 'quick', 'matter', 'held', 'supplier', 'nvda', 'im', 'spare', 'yall', 'ill', 'homeless', 'practical', 'anywhere', 'hassle', 'putting', 'mouth', 'georgia', 'greatest', 'comeback', 'amd', 'maga', 'mid', 'primed', 'rip', 'face', 'rally', 'healthy', 'scales', 'exist', 'unable', 'bunch', 'players', 'survival', 'experts', 'swing', 'trader', 'plenty', 'winners', 'longs', 'stress', 'peak', 'ala', 'believe', 'ticket', 'wear', 'mask', 'eating', 'washing', 'law', 'logics', 'science', 'defies', 'incredible', 'yr', 'small', 'following', 'views', 'rising', 'retests', 'pent', 'gons', 'drone', 'bmw', 'suvs', 'boys', 'miracle', 'f', 'senate', 'easy', 'hi', 'dogenaries', 'shorty', 'meet', 'gary', 'fuckers', 'shorties', 'bla', 'fuk', 'vote', 'listed', 'coinbase', 'rich', 'ta', 'rise', 'positive', 'powerwall', 'demand', 'chip', 'shortage', 'adding', 'renewable', 'unite', 'discussing', 'b', 'cathie', 'wood', 'jack', 'dorsey', 'stop', 'purchases', 'tell', 'kid', 'shot', 'sideways', 'patience', 'usual', 'bleed', 'dry', 'wads', 'hate', 'mms', 'crashing', 'gooooo', 'letting', 'scared', 'mommy', 'instacart', 'achieve', 'multi', 'hundred', 'thousand', 'percent', 'explosion', 'told', 'twoh', 'gocart', 'remove', 'aiming', 'canada', 'ticker', 'parent', 'hands', 'rumored', 'highly', 'ontario', 'based', 'google', 'structure', 'subpenny', 'outstanding', 'expecting', 'scaling', 'load', 'biotechs', 'joking', 'plane', 'sight', 'gee', 'usually', 'aint', 'bummer', 'blow', 'theres', 'idea', 'unadulterated', 'pain', 'fundermental', 'correlates', 'wallstreetbets', 'woke', 'spike', 'alfi', 'jelly', 'fsr', 'suv', 'sahres', 'lets', 'ya', 'aol', 'evaluation', 'instant', 'permits', 'suck', 'bz', 'futures', 'mark', 'session', 'touch', 'harry', 'dent', 'faith', 'stat', 'compact', 'sports', 'fudge', 'averaged', 'mins', 'spy', 'gave', 'mclaren', 'oh', 'hills', 'ha', 'fact', 'screaming', 'bloody', 'murder', 'fooled', 'drops', 'entirely', 'pricks', 'wasting', 'zero', 'bear', 'case', 'hey', 'sociopaths', 'zoom', 'buh', 'focused', 'deck', 'slow', 'dance', 'timing', 'beside', 'uavs', 'early', 'stages', 'projected', 'grow', 'alpp', 'diversified', 'subsidiaries', 'air', 'force', 'example', 'acquiring', 'hence', 'undervalued', 'applied', 'engaged', 'donohoe', 'advisory', 'fast', 'approval', 'experiencing', 'delays', 'covid', 'number', 'applications', 'mooooonn', 'stirring', 'pot', 'bit', 'partnered', 'ath', 'towards', 'weak', 'tip', 'passed', 'sob', 'linking', 'volumes', 'spiking', 'hitting', 'mostly', 'surge', 'according', 'recorded', 'single', 'history', 'concentrated', 'among', 'faamg', 'amzn', 'googl', 'however', 'whereupon', 'faamgs', 'remains', 'unclear', 'places', 'bearish', 'funded', 'ventures', 'sick', 'enter', 'eaviation', 'morgan', 'stanley', 'note', 'via', 'offers', 'discounted', 'sees', 'wind', 'promised', 'savings', 'shorterrange', 'sportsutility', 'comes', 'slip', 'concern', 'string', 'publicity', 'soured', 'customer', 'raised', 'bofa', 'securities', 'fell', 'asleep', 'luckily', 'thses', 'cashing', 'uptrend', 'trendline', 'intact', 'nap', 'welcome', 'moderna', 'dunno', 'lucky', 'sort', 'adoption', 'depressing', 'mercedes', 'flush', 'clueless', 'desperate', 'speakers', 'digit', 'mafia', 'digits', 'wonderful', 'successful', 'decades', 'patiently', 'rushed', 'alas', 'late', 'advise', 'sock', 'waver', 'twitter', 'tel', 'diversify', 'portfolio', 'float', 'march', 'accumulating', 'besides', 'amazing', 'eod', 'cult', 'grimes', 'pb', 'provides', 'dividend', 'arrogant', 'disgusting', 'head', 'ass', 'puppy', 'belongs', 'fgen', 'jump', 'list', 'priming', 'kinda', 'roadster', 'garage', 'peter', 'rawlinson', 'underpromises', 'overdeliver', 'investigations', 'trials', 'fines', 'obvi', 'suit', 'anyday', 'delivey', 'stats', 'integral', 'promising', 'carbon', 'capture', 'devices', 'operation', 'r', 'fluor', 'patented', 'innovative', 'gen', 'modular', 'executionsm', 'approach', 'tonneperyear', 'facility', 'surely', 'vastly', 'improved', 'flr', 'climate', 'wallet', 'listening', 'pinned', 'max', 'food', 'chain', 'grlt', 'wondered', 'hasnt', 'stronger', 'investigated', 'doj', 'investigation', 'bad', 'fake', 'volvo', 'faster', 'porsche', 'landlord', 'charge', 'inside', 'wholly', 'batman', 'xpev', 'aug', 'hurry', 'acb', 'globally', 'paid', 'gooooooo', 'sidelines', 'device', 'transferring', 'impatient', 'patient', 'wb', 'itm', 'ortex', 'reported', 'debunked', 'hedgefunds', 'falsely', 'reporting', 'shortlong', 'imminent', 'macd', 'shape', 'c', 'repeat', 'sweepers', 'swift', 'signal', 'tears', 'vibes', 'goooo', 'hopes', 'hurt', 'ayiiiiieee', 'broken', 'yeah', 'wayy', 'excited', 'mastermind', 'boom', 'lord', 'yeeeeeeeeeeeees', 'lfg', 'yess', 'strike', 'lotto', 'fighting', 'lives', 'impressed', 'greeeennnn', 'pps', 'charging', 'germany', 'teslanorth', 'sel', 'tried', 'transformative', 'backdrop', 'terribly', 'boring', 'dogecoin', 'hanging', 'cyber', 'town', 'jpm', 'overdue', 'thise', 'sndl', 'extremely', 'trend', 'october', 'weekends', 'platforms', 'helps', 'fellow', 'captains', 'approved', 'ecofriendly', 'miner', 'farm', 'computing', 'wisconsin', 'mine', 'streamline', 'sale', 'exchange', 'succesful', 'splash', 'investing', 'established', 'executives', 'reputations', 'luck', 'except', 'angry', 'fastly', 'smooth', 'climb', 'throwing', 'scalp', 'predicted', 'correctly', 'coiled', 'springs', 'rocketship', 'skyrocketting', 'bro', 'twice', 'fax', 'mustang', 'refuses', 'tenet', 'parking', 'gim', 'w', 'hr', 'zone', 'goodbye', 'poop', 'tomorrow', 'guaranteed', 'income', 'innovation', 'afternoon', 'everywhere', 'chips', 'provided', 'indie', 'calling', 'bigly', 'commodity', 'supercycle', 'fuelled', 'powering', 'electrification', 'wwwforbescomcdnampproje', 'floor', 'added', 'pounding', 'whore', 'die', 'unlikely', 'aviation', 'reweighed', 'doubles', 'cut', 'minimum', 'facts', 'taken', 'shed', 'cat', 'meow', 'cats', 'diamond', 'handsssssssssssssssssssssss', 'u', 'bitch', 'hahahhahaha', 'af', 'watches', 'penguins', 'exponential', 'runup', 'sir', 'semi', 'conductor', 'bitcoin', 'whale', 'spread', 'mentally', 'weakening', 'inevitable', 'backing', 'walls', 'stopping', 'movement', 'retest', 'trying', 'beast', 'contained', 'dummies', 'damn', 'rollers', 'pointing', 'esther', 'students', 'joining', 'program', 'migrating', 'classes', 'enjoyed', 'refer', 'soo', 'fucks', 'sake', 'dow', 'slumps', 'pulling', 'records', 'survey', 'shows', 'americans', 'prepping', 'inflation', 'issue', 'eom', 'hedgies', 'keeping', 'especially', 'loading', 'levels', 'test', 'scare', 'orchestrated', 'illegitimate', 'reconstruction', 'puts', 'buyin', 'ending', 'quite', 'scrubs', 'scrape', 'scraps', 'post', 'tanking', 'manipulating', 'mimics', 'standing', 'everyday', 'return', 'nikola', 'steve', 'jobs', 'death', 'agree', 'merge', 'nola', 'controls', 'universe', 'intention', 'ignite', 'revolution', 'preference', 'topoftheline', 'supercars', 'unlucky', 'anyways', 'daddy', 'scenes', 'impeccable', 'marsss', 'maxim', 'donald', 'loan', 'jk', 'intraday', 'numbers', 'consolidation', 'said', 'religiously', 'bucks', 'grand', 'round', 'abouts', 'convicted', 'airlines', 'plays', 'boned', 'ripping', 'innd', 'alltimehigh', 'decides', 'correct', 'buys', 'posted', 'speculation', 'several', 'converging', 'factors', 'fodder', 'glta', 'erj', 'taxi', 'evtol', 'lowest', 'riskabout', 'division', 'agenda', 'smear', 'trucks', 'hated', 'often', 'favors', 'bidder', 'wsb', 'crew', 'setup', 'stopped', 'vwap', 'downtrend', 'da', 'spacs', 'fingers', 'crossedjust', 'govt', 'gas', 'falling', 'tendies', 'exercise', 'beyondchart', 'rounding', 'worries', 'rush', 'slap', 'writers', 'afford', 'sucks', 'boa', 'raises', 'yolo', 'epic', 'exigently', 'raw', 'absurdity', 'industrial', 'midnext', 'propellant', 'dips', 'goooooooooooooooooooooo', 'clients', 'hugeeeeeee', 'nibble', 'turbulent', 'adjusts', 'winning', 'chatroom', 'public', 'violent', 'rips', 'peoples', 'faces', 'dumb', 'dumbs', 'realized', 'inflection', 'trolls', 'cry', 'bubble', 'crying', 'irrelevant', 'ratios', 'listen', 'daysweeks', 'relentless', 'manipulationpinning', 'fucced', 'ar', 'maintains', 'burry', 'rest', 'knowing', 'retards', 'talking', 'nonsense', 'mansion', 'babies', 'opex', 'repent', 'hatred', 'carrying', 'destroy', 'peace', 'present', 'aka', 'gamma', 'setting', 'mother', 'cathy', 'indicators', 'trash', 'obviously', 'girlfriend', 'sign', 'dumps', 'deep', 'drawdown', 'poor', 'performance', 'relatively', 'pricesales', 'ratio', 'information', 'debt', 'non', 'existent', 'initially', 'burning', 'software', 'generally', 'gross', 'margins', 'suppressed', 'pricing', 'breakeven', 'exactly', 'pin', 'log', 'frustration', 'wet', 'dream', 'trap', 'disappear', 'supports', 'daddydoge', 'expiring', 'fk', 'sog', 'lmao', 'evgo', 'daytrade', 'fucken', 'rock', 'virgin', 'galactic', 'howdy', 'doodie', 'madness', 'accumulation', 'prob', 'rewarded', 'checked', 'teladoc', 'prior', 'forgot', 'squeezes', 'covering', 'pushes', 'boosted', 'hod', 'fed', 'comment', 'wrong', 'become', 'richer', 'poorer', 'gunna', 'closes', 'hydrogen', 'bev', 'fcev', 'famous', 'holder', 'toddler', 'doable', 'suddenly', 'increased', 'haha', 'heere', 'lineup', 'tuesday', 'clown', 'speaking', 'cnbc', 'goneeeee', 'found', 'breaks', 'nation', 'donate', 'battle', 'music', 'vw', 'jim', 'paulson', 'hodling', 'prick', 'brings', 'paulsen', 'squad', 'ppwlo', 'match', 'heaven', 'bringjng', 'later', 'foxbusiness', 'together', 'silently', 'fridays', 'stckpronewsarbkf', 'rippppppppp', 'losing', 'averaging', 'points', 'shoots', 'accumulate', 'wealthy', 'fellows', 'idiot', 'didnt', 'reminder', 'imo', 'wants', 'lackluster', 'liking', 'hits', 'rallying', 'pile', 'dough', 'shall', 'lighter', 'main', 'concerns', 'powerful', 'distance', 'seee', 'started', 'ship', 'bo', 'thompson', 'addressed', 'rcat', 'stated', 'dilution', 'runway', 'bank', 'correction', 'trimming', 'european', 'cmon', 'sectors', 'resistance', 'savvy', 'grasping', 'importance', 'cells', 'antibodies', 'war', 'variants', 'becomes', 'verb', 'oversold', 'funny', 'blockfi', 'equity', 'accounts', 'voyager', 'quarterly', 'gone', 'three', 'quarters', 'pretend', 'concerned', 'manufacturer', 'unattended', 'overnight', 'lest', 'catch', 'condition', 'applies', 'interested', 'ipos', 'kraken', 'message', 'europe', 'tractor', 'xmas', 'killing', 'saw', 'koinfold', 'promise', 'worst', 'wan', 'mow', 'lawn', 'stake', 'mining', 'solarcity', 'mainly', 'banning', 'efficiency', 'exceeding', 'requirements', 'tho', 'dickheads', 'floodgates', 'sellers', 'general', 'tickers', 'switch', 'arrived', 'couv', 'bmix', 'ttcm', 'etek', 'haon', 'vuzi', 'tmetruthfultraders', 'group', 'nev', 'titan', 'tons', 'institutional', 'happier', 'suggestion', 'manipulated', 'sec', 'select', 'grab', 'girls', 'mentioned', 'superskynet', 'usa', 'indices', 'surprised', 'longer', 'anticipating', 'favour', 'nontypical', 'northern', 'prize', 'possession', 'smells', 'solution', 'myth', 'legend', 'interview', 'stream', 'youtube', 'sing', 'caraoke', 'explain', 'needed', 'flushed', 'leg', 'overpriced', 'myriad', 'focus', 'angle', 'copper', 'stimuli', 'payment', 'balloon', 'narrative', 'cleanspark', 'responsible', 'boast', 'figure', 'presentation', 'roadshow', 'meeting', 'okay', 'fees', 'risks', 'awesome', 'revenues', 'metamaterials', 'trouble', 'mi', 'cute', 'trident', 'missile', 'reserve', 'ocean', 'scream', 'desperation', 'bloviation', 'incite', 'panicthat', 'tiers', 'yammer', 'wont', 'ark', 'microsoft', 'genomics', 'lack', 'intellect', 'education', 'doesnt', 'amount', 'compounds', 'returns', 'righteous', 'panel', 'passes', 'initiatives', 'electricity', 'boosting', 'cleaner', 'fossil', 'fuels', 'capturing', 'plantsindustries', 'atmosphere', 'fan', 'picked', 'feels', 'lots', 'lines', 'code', 'written', 'related', 'updated', 'completion', 'timeline', 'estimated', 'path', 'testing', 'august', 'september', 'campaign', 'cdc', 'malicious', 'intent', 'country', 'registrations', 'retirement', 'tiiiiiiiiiiiiiiiiiiime', 'lightning', 'nnnn', 'chances', 'agreement', 'accept', 'embarrassing', 'delaney', 'cautiously', 'optimistic', 'raising', 'eps', 'worried', 'reiterate', 'backward', 'math', 'fifth', 'grader', 'corrupted', 'course', 'goldman', 'dive', 'wise', 'cautious', 'nauseous', 'altitude', 'sickness', 'quickness', 'stuck', 'yearning', 'tide', 'turning', 'tisk', 'hurts', 'bay', 'maintain', 'bankrupt', 'scam', 'family', 'blind', 'enemy', 'ignorance', 'gl', 'article', 'tomo', 'chat', 'questions', 'welcomed', 'nuts', 'rarely', 'futes', 'confused', 'matching', 'uplists', 'tsx', 'phuck', 'failing', 'jp', 'checks', 'volatility', 'alibaba', 'spacex', 'tiny', 'heres', 'reversal', 'expire', 'vision', 'devil', 'destruction', 'prevail', 'believing', 'imaginable', 'dedication', 'succeed', 'mater', 'obstacles', 'believes', 'ambitions', 'doubters', 'ambition', 'destroying', 'gods', 'talents', 'stand', 'overcome', 'paypall', 'employees', 'doors', 'beat', 'alerted', 'despite', 'conditions', 'educational', 'weekly', 'challenges', 'raffles', 'chatactivity', 'rewards', 'registration', 'original', 'previously', 'gotten', 'frank', 'copies', 'context', 'regurgitated', 'admits', 'accelerated', 'moreover', 'accelerate', 'dejavu', 'shopping', 'strikes', 'included', 'november', 'newly', 'minted', 'nutty', 'recalling', 'bolts', 'asking', 'problem', 'anomalies', 'nonglare', 'windshields', 'transparent', 'visors', 'invisible', 'antenna', 'improving', 'lidar', 'jumping', 'gun', 'earlier', 'sector', 'talks', 'challenged', 'sand', 'closing', 'basis', 'therefore', 'int', 'hex', 'asap', 'lololol', 'cuz', 'uglydorky', 'sin', 'thursday', 'trapezoidlike', 'decent', 'hyper', 'dormant', 'sit', 'comments', 'fakers', 'door', 'handles', 'ema', 'shoutout', 'testers', 'shown', 'oversight', 'safely', 'wide', 'follows', 'shine', 'saved', 'families', 'accident', 'caused', 'weather', 'tires', 'hot', 'referrals', 'acquco', 'startups', 'prosper', 'ys', 'headline', 'table', 'resume', 'pushed', 'story', 'adjusting', 'forecast', 'fundamentals', 'build', 'giga', 'couldnt', 'gigs', 'simultaneously', 'arkk', 'hilarious', 'approaching', 'aths', 'january', 'mf', 'inf', 'bell', 'relative', 'strength', 'overall', 'continue', 'assigned', 'fabulous', 'sometimes', 'expects', 'li', 'superhyper', 'ferrari', 'lamborghini', 'evolution', 'highway', 'definitely', 'stack', 'complex', 'originally', 'goooooo', 'sexy', 'living', 'shareholder', 'takes', 'overseas', 'coincidental', 'judge', 'batten', 'deny', 'mtd', 'philip', 'morris', 'patents', 'invalidated', 'busy', 'youz', 'base', 'aligned', 'insights', 'peep', 'desire', 'hovering', 'fret', 'cave', 'chew', 'skips', 'offense', 'wannabe', 'advertise', 'remotely', 'le', 'guerre', 'ok', 'pumps', 'fantasy', 'imaginary', 'planet', 'colonizations', 'george', 'webcast', 'greatly', 'final', 'statement', 'gasscented', 'fragrance', 'gt', 'saving', 'environment', 'diamonds', 'balls', 'orbit', 'tomaroww', 'reddit', 'army', 'complaints', 'alot', 'tree', 'shaking', 'considering', 'tests', 'cock', 'teslaaaaa', 'continuation', 'recovery', 'shitting', 'bricks', 'alien', 'reference', 'linktreeanalyzeandtrade', 'todays', 'gut', 'wrenchong', 'sine', 'wave', 'ive', 'expd', 'bouncing', 'bot', 'powell', 'shits', 'golden', 'pokemon', 'cards', 'adults', 'collect', 'defense', 'pretty', 'victories', 'claim', 'terms', 'testifying', 'front', 'congress', 'speech', 'sls', 'brain', 'iq', 'hint', 'continues', 'gorgeous', 'luxo', 'swap', 'supergrowing', 'bounces', 'gay', 'growling', 'banks', 'losers', 'jpmorgan', 'prolly', 'radar', 'fam', 'spelled', 'backwards', 'alset', 'aei', 'spell', 'tacos', 'semiconductors', 'silly', 'large', 'prints', 'blue', 'kicking', 'kill', 'confirmed', 'mints', 'ec', 'ban', 'emit', 'capital', 'bigcap', 'joy', 'tap', 'notice', 'feds', 'pissed', 'leaps', 'prepare', 'dayspull', 'climbing', 'probably', 'tmrw', 'illegally', 'pictures', 'opened', 'screen', 'facing', 'critical', 'loka', 'tom', 'fuckin', 'fault', 'enrty', 'tf', 'attttttttt', 'alright', 'bieng', 'progress', 'dydd', 'yas', 'blessed', 'mutha', 'milliom', 'supplydemand', 'legacy', 'decade', 'autos', 'sadly', 'doomed', 'careful', 'misled', 'lights', 'guide', 'funding', 'depending', 'train', 'silver', 'sighted', 'modes', 'perhaps', 'film', 'etc', 'drugs', 'realizes', 'scalable', 'waymo', 'kitchenware', 'floodgate', 'squeezing', 'skinning', 'bone', 'crushing', 'advised', 'shameless', 'meritless', 'inndletsgo', 'traderz', 'upon', 'piously', 'important', 'dumbasses', 'youre', 'rules', 'shouldnt', 'envy', 'respect', 'artist', 'wage', 'announcing', 'south', 'korea', 'insideevs', 'master', 'recommends', 'yo', 'touching', 'pathetic', 'resort', 'literal', 'manipation', 'mad', 'sitting', 'trillions', 'normal', 'cheat', 'stealing', 'bullshit', 'walking', 'walk', 'shortsbears', 'cleaning', 'cents', 'pluto', 'multibillion', 'references', 'conference', 'codeveloped', 'announcements', 'theft', 'losses', 'excellent', 'kept', 'tweaks', 'slightly', 'recognizes', 'opens', 'steer', 'nimble', 'handling', 'tight', 'turns', 'somebody', 'photoshop', 'window', 'fearful', 'replacing', 'rare', 'earth', 'asia', 'fry', 'suckers', 'garbage', 'yields', 'agent', 'particular', 'attack', 'criminals', 'seat', 'deserved', 'penant', 'begun', 'different', 'satirical', 'recklessness', 'lmaoooooooooooo', 'textbook', 'bleeding', 'lazering', 'teslaq', 'circus', 'played', 'theater', 'porn', 'tape', 'chairing', 'déjà', 'vu', 'wo', 'anticipate', 'aggressive', 'alignment', 'economy', 'involved', 'aircraft', 'bonus', 'challenge', 'clear', 'democrats', 'capitalism', 'om', 'poised', 'drop', 'doom', 'gloom', 'subsidies', 'payer', 'musks', 'perfection', 'sink', 'slump', 'nutshell', 'hf', 'inflationcovid', 'caught', 'excellence', 'friends', 'broader', 'stupid', 'riding', 'immediately', 'reports', 'purchasers', 'credits', 'qtrs', 'qtr', 'substantially', 'incurring', 'paper', 'lemmings', 'loooool', 'jab', 'hoax', 'immunity', 'fled', 'state', 'jet', 'republicanled', 'election', 'reform', 'bills', 'email', 'regular', 'stocktwits', 'criteria', 'regardless', 'postings', 'curious', 'minds', 'advance', 'meter', 'calculates', 'average', 'ytd', 'simple', 'observe', 'performing', 'determined', 'tops', 'roi', 'forthcoming', 'anticipated', 'armageddon', 'depression', 'tdtiahth', 'celebrity', 'bath', 'water', 'kidding', 'unreliable', 'fatal', 'lemmimgs', 'blackmail', 'iceberg', 'permabull', 'posts', 'continuing', 'biz', 'born', 'value', 'political', 'rhetoric', 'effect', 'study', 'minute', 'fav', 'drink', 'ice', 'heard', 'pooped', 'peed', 'pants', 'diligence', 'socioeconomic', 'et', 'al', 'thereafter', 'greeting', 'haters', 'jawboning', 'newsworthy', 'emails', 'reliable', 'publishers', 'imho', 'sheeples', 'queue', 'snippet', 'infected', 'demented', 'dramatically', 'implode', 'fyi', 'wk', 'health', 'reads', 'crashes', 'links', 'section', 'ranked', 'follower', 'scored', 'guidehouse', 'certain', 'variables', 'determine', 'placement', 'leaders', 'alter', 'strategic', 'expand', 'resources', 'improve', 'faulted', 'overpromising', 'marketing', 'capabilities', 'led', 'actual', 'issues', 'preceded', 'pandemic', 'whose', 'traceable', 'forms', 'handy', 'era', 'precisely', 'policy', 'criticized', 'authorities', 'tabs', 'individuals', 'card', 'transactions', 'france', 'french', 'macron', 'tightening', 'anticoronavirus', 'measures', 'workers', 'required', 'vaccinated', 'citizens', 'socalled', 'passports', 'visit', 'leisure', 'cultural', 'venues', 'secretary', 'sajid', 'javid', 'selfisolating', 'home', 'lateral', 'came', 'grateful', 'received', 'jabs', 'vaccine', 'symptoms', 'mild', 'unjustified', 'combined', 'crumble', 'indirectly', 'separate', 'entity', 'popularity', 'genius', 'showmanship', 'remarkable', 'hyping', 'independent', 'thinkers', 'stands', 'false', 'truly', 'mr', 'timed', 'modus', 'operandi', 'distract', 'subtle', 'creative', 'anymore', 'becoming', 'predictable', 'person', 'utilize', 'shines', 'optimism', 'movies', 'became', 'con', 'modern', 'liar', 'fuzzy', 'seeing', 'cancel', 'awareness', 'sucker', 'meanwhile', 'widely', 'teslemmings', 'eap', 'circle', 'guru', 'projections', 'availability', 'painfully', 'member', 'pushing', 'pretending', 'miners', 'electrons', 'endless', 'headed', 'previous', 'tanks', 'secret', 'local', 'dealership', 'rental', 'merry', 'catastrophic', 'figured', 'mechanic', 'melts', 'drives', 'wanted', 'quietly', 'embarrassed', 'popping', 'libs', 'admitting', 'idiotic', 'engulfing', 'candle', 'parabolic', 'renowned', 'doctor', 'exposes', 'originated', 'bubblelike', 'signs', 'flags', 'breadth', 'narrowing', 'xlf', 'xle', 'iwm', 'participating', 'longest', 'toppy', '𝐔𝐏𝐃𝐀𝐓𝐄', '𝑊𝐸', '𝐻𝐴𝑉𝐸', '𝑅𝐸𝐶𝐼𝐸𝑉𝐸𝐷', '𝑇𝑅𝐼𝐿𝐿𝐼𝑂𝑁', '𝑁𝐸𝑊', '𝑂𝑅𝐷𝐸𝑅𝑆', 'trucksmonth', 'septemeber', 'moneymade', 'cc', 'winter', 'screwing', 'bagholders', 'response', 'blokes', 'laugh', 'beaches', 'hahaha', 'twats', 'defective', 'videos', 'terrifying', 'forced', 'steering', 'wheel', 'autopilot', 'objects', 'horrible', 'causing', 'shocked', 'permit', 'convince', 'review', 'submitted', 'upgrade', 'inflated', 'verge', 'historic', 'wework', 'photo', 'uploaded', 'purports', 'elderly', 'struggling', 'medical', 'worse', 'asks', 'pesky', 'carriers', 'lockdown', 'thy', 'easter', 'bunny', 'eliminate', 'heist', 'corporate', 'lapdog', 'boomers', 'insanity', 'bar', 'restaurant', 'jail', 'fail', 'status', 'sentence', 'fine', 'monopolize', 'footage', 'circulating', 'prime', 'minister', 'jacinda', 'ardern', 'zealand', 'reject', 'modelit', 'sad', 'recreated', 'attractivesold', 'regrets', 'abnb', 'theyll', 'collected', 'scalped', 'faang', 'baked', 'scammers', 'cnbsnewslivedocumentaries', 'drag', 'priority', 'st', 'transitory', 'lolosers', 'baggies', 'estate', 'correlated', 'behave', 'similarly', 'woman', 'dementia', 'bidens', 'investments', 'til', 'stops', 'granted', 'qqq', 'buckle', 'fragment', 'lending', 'expense', 'bsf', 'rotflmao', 'suffer', 'vaccines', 'mutations', 'evolving', 'adapting', 'immune', 'compromised', 'natural', 'body', 'programmed', 'strain', 'compromise', 'reign', 'terrorism', 'coward', 'blocks', 'favor', 'dies', 'lying', 'adapt', 'unvaccinated', 'encourage', 'mutate', 'dying', 'surviving', 'lessons', 'evade', 'everybody', 'descending', 'sleepy', 'enron', 'pooop', 'en', 'route', 'fkn', 'assured', 'severe', 'cure', 'coronavirus', 'rex', 'wrathful', 'smoking', 'pack', 'fork', 'pig', 'doordash', 'newer', 'shade', 'ugly', 'divert', 'attention', 'billionaires', 'wrote', 'supposed', 'piec', 'eof', 'inauguration', 'drawing', 'realistic', 'wtf', 'moved', 'unscammed', 'mor', 'buds', 'inhale', 'fishing', 'jammed', 'j', 'parasite', 'printer', 'darkpools', 'dookie', 'punch', 'wonder', 'insiders', 'blood', 'ph', 'legooo', 'competitiveness', 'paradise', 'papa', 'victim', 'yummy', 'pts', 'bc', 'useless', 'delist', 'print', 'absolutely', 'roasted', 'writing', 'bunker', 'jawbone', 'specialist', 'ignore', 'cronies', 'whitehouse', 'albeit', 'bullsit', 'discloses', 'screw', 'united', 'america', 'fkd', 'loser', 'favs', 'nclh', 'deception', 'booted', 'spot', 'minimi', 'attracting', 'compete', 'brighter', 'prospect', 'victimizing', 'rug', 'yikes', 'accurate', 'producing', 'acquire', 'exit', 'remaining', 'exiting', 'blame', 'advisers', 'aware', 'lawsuits', 'property', 'lavishly', 'preparation', 'phone', 'poopy', 'balance', 'cutting', 'dowb', 'wouldnt', 'knife', 'preearnings', 'shitfest', 'puking', 'stellar', 'dude', 'cannibalizing', 'date', 'strategies', 'ages', 'guidance', 'heating', 'targeting', 'benzinga', 'hackers', 'attacked', 'ramsonmware', 'turd', 'overload', 'spoke', 'crappy', 'idiots', 'irs', 'dirt', 'staying', 'seas', 'fixed', 'btw', 'traps', 'create', 'weep', 'nightmare', 'joke', 'weapon', 'lithium', 'missiles', 'sakes', 'stochastic', 'stretched', 'overbought', 'downnnnnnnnnnnnnn', 'bologna', 'bread', 'legal', 'greetings', 'aforementioned', 'whipsaw', 'whacking', 'courage', 'juice', 'todaysc', 'volatile', 'shy', 'sleep', 'stretching', 'lod', 'chub', 'exchanges', 'canceling', 'mistake', 'limit', 'v', 'behavior', 'indicates', 'liquidate', 'signalling', 'press', 'unknowns', 'signally', 'lies', 'hates', 'crackdown', 'unprofitable', 'slowly', 'corrects', 'speed', 'dial', 'mom', 'teasing', 'resigns', 'auuuu', 'smell', 'fresh', 'doji', 'delorean', 'el', 'camino', 'scifi', 'movie', 'wallets', 'wives', 'couch', 'rent', 'bulllll', 'lunch', 'brothers', 'sisters', 'preparing', 'fart', 'sooooo', 'pressure', 'jesus', 'homies', 'spit', 'easiest', 'hadadadaduoooooo', 'domination', 'directed', 'weed', 'mmnff', 'role', 'brand', 'dominate', 'warren', 'buffet', 'style', 'overrrrrrrr', 'pocket', 'indexes', 'smartoptionsai', 'lottoooooooo', 'pussy', 'waterfall', 'flushing', 'omg', 'trapping', 'gona', 'yellen', 'yelled', 'inflating', 'wrecked', 'shoulda', 'suicide', 'lmfao', 'bond', 'prop', 'callsprd', 'typical', 'flood', 'shitcoin', 'fr', 'sells', 'cooked', 'yesterdays', 'ahahahahahaha', 'unloaded', 'pits', 'drawn', 'fashion', 'valued', 'crawl', 'flat', 'energized', 'fat', 'teleportation', 'vol', 'premarket', 'timber', 'specimen', 'stimulus', 'serve', 'unemployment', 'etal', 'jawboners', 'smacking', 'pumper', 'silent', 'somehow', 'scammer', 'nobody', 'lately', 'validvalidated', 'indicesfutures', 'serving', 'unregulated', 'sympathetic', 'dogs', 'hyped', 'appear', 'liberal', 'areas', 'financing', 'dining', 'qsr', 'scummy', 'wonders', 'peaks', 'horizon', 'stellantis', 'ram', 'conversation', 'goodnight', 'earned', 'battlefield', 'fuel', 'cell', 'powered', 'effective', 'evs', 'refill', 'baggers', 'bagger', 'eeewwww', 'evening', 'dot', 'com', 'suggested', 'cnn', 'cheers', 'tomorrowabsolute', 'deflation', 'demonstrate', 'ended', 'collapse', 'decay', 'rammo', 'demise', 'ballz', 'bound', 'cycle', 'ac', 'meaning', 'oink', 'dearly', 'devastating', 'fleecing', 'feces', 'excrement', 'doodoo', 'diapers', 'rsi', 'adx', 'nasty', 'triangle', 'signaling', 'heading', 'abyss', 'activating', 'negativity', 'almighty', 'ruler', 'turds', 'watcher', 'saint', 'crown', 'father', 'felon', 'resign', 'vacuum', 'cleaners', 'alone', 'adds', 'warn', 'fullself', 'loses', 'lawsuit', 'loans', 'pledged', 'sound', 'crumbling', 'promotion', 'pays', 'branson', 'burned', 'flight', 'fragile', 'gigantic', 'leads', 'leaving', 'origin', 'poetic', 'verses', 'stinky', 'smelly', 'cashed', 'spreads', 'sweet', 'l', 'juncture', 'rebounded', 'tne', 'sma', 'delayedactionable', 'jul', 'atm', 'gladly', 'deserve', 'impairment', 'reaching', 'assuming', 'rough', 'estimate', 'dummy', 'unfortunately', 'dumping', 'scams', 'shame', 'pumping', 'sht', 'nflx', 'crapper', 'believed', 'bag', 'owwww', 'stink', 'crosses', 'fa', 'faded', 'fade', 'lads', 'boot', 'breath', 'mud', 'puddle', 'selloff', 'wink', 'puke', 'fantasizing', 'lovers', 'rid', 'proposal', 'deficient', 'nuclear', 'imports', 'russia', 'middle', 'east', 'supplies', 'replace', 'oil', 'gotcha', 'dat', 'slide', 'gotemmmm', 'soooo', 'electrica', 'promoting', 'destine', 'discontinued', 'arnt', 'boy', 'nail', 'coffin', 'negligible', 'dreaming', 'existence', 'drooling', 'indeed', 'quits', 'fraudulently', 'btd', 'moment', 'rabbits', 'gooo', 'diligenc', 'whats', 'rblx', 'palantir', 'sq', 'qsi', 'mo', 'weakness', 'bashed', 'stonks', 'jay', 'pow', 'hahahahaha', 'winding', 'awful', 'overvalue', 'futuristic', 'darling', 'doubling', 'flash', 'pace', 'christmas', 'granny', 'moth', 'school', 'prom', 'dress', 'welfare', 'dusty', 'horrendous', 'headlines', 'roflmfao', 'pics', 'camouflage', 'india', 'leftover', 'lovely', 'boutta', 'dang', 'anus', 'hangs', 'burst', 'toilet', 'bowl', 'yikessss', 'hung', 'generous', 'donations', 'crack', 'wen', 'democratic', 'gearing', 'memory', 'likes', 'republican', 'voters', 'booooommm', 'cupcake'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGvGRY0aWNR7"
      },
      "source": [
        "vocab = \" \"\n",
        "vocab.join(twit_w2v.wv.vocab.keys())\n",
        "vocablist = []\n",
        "vocablist.append(vocab)\n",
        "t = tuple(twit_w2v.wv.vocab.keys())"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcNXmuIScvqb"
      },
      "source": [
        "tl = list(t)"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92AMiqVtqz88"
      },
      "source": [
        ""
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyj-EU1ErE6R",
        "outputId": "a3300332-86a0-4760-cebb-be7ec3cb97c3"
      },
      "source": [
        "tl"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGAa1fiFEuer",
        "outputId": "80d63431-38da-4207-faff-d22406d3d5ba"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# build the word vector\n",
        "# using term frequencey-inverse document frequency \n",
        "# to determine the importance of a word against a corpus\n",
        "print('building tf-idf matrix ...')\n",
        "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
        "\n",
        "\n",
        "# np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_test))])\n",
        "# matrix = vectorizer.fit_transform([x.words for x in x_train])\n",
        "# vocab = [x.words for x in x_train]\n",
        "\n",
        "vocab = \" \"\n",
        "vocab.join(twit_w2v.wv.vocab.keys())\n",
        "vocablist = []\n",
        "vocablist.append(vocab)\n",
        "matrix = vectorizer.fit(corpus)\n",
        "# matrix = vectorizer.fit_transrm(vocab)\n",
        "vectorizer.transform(corpus)\n",
        "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "print('vocab size :', len(tfidf))\n"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tf-idf matrix ...\n",
            "vocab size : 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5dXNK9b0_5",
        "outputId": "da28b47f-73fd-4fe0-e7fa-fa24cd2ada43"
      },
      "source": [
        "tfidf"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 1.0,\n",
              " '?': 1.2231435513142097,\n",
              " 'I': 1.2231435513142097,\n",
              " 'c': 1.0689928714869514,\n",
              " 'd': 1.0,\n",
              " 'e': 1.0,\n",
              " 'f': 1.1431008436406733,\n",
              " 'h': 1.0,\n",
              " 'i': 1.0,\n",
              " 'm': 1.0689928714869514,\n",
              " 'n': 1.0,\n",
              " 'o': 1.0,\n",
              " 'r': 1.0689928714869514,\n",
              " 's': 1.0,\n",
              " 't': 1.0,\n",
              " 'u': 1.0689928714869514}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giW57Ubhz4Ew",
        "outputId": "48a7e49e-6778-4139-8bd4-706cdfac1f32"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmzU59oEuH_"
      },
      "source": [
        "def buildWordVector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += twit_word_model[word].reshape((1, size)) * tfidf[word]\n",
        "            count += 1.\n",
        "        except KeyError: # handling the case where the token is not\n",
        "                         # in the corpus. useful for testing.\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZpz7kt1upn"
      },
      "source": [
        "def buildWordVector2(tokens, size):\n",
        "    # vec = np.zeros(size).reshape((1, size))\n",
        "    vec = np.zeros(size)\n",
        "    count = 0.\n",
        "    for word in tokens:\n",
        "        vec += twit_word_model[word]\n",
        "    return vec"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kovUSveI3p5K"
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhNnLd-R2Mp"
      },
      "source": [
        "def printstuff(stuff, size):\n",
        "  print(stuff)"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywFocP1UeAoc"
      },
      "source": [
        "train_vecs_w2v = np.concatenate([buildWordVector2(z, n_dim) for z in tqdm(map(lambda x: x.words, x_train))])\n",
        "# train_vecs_w2v = scale(train_vecs_w2v)\n",
        "\n",
        "\n",
        "test_vecs_w2v = np.concatenate([buildWordVector2(z, n_dim) for z in tqdm(map(lambda x: x.words, x_test))])\n",
        "# test_vecs_w2v = scale(test_vecs_w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNmiK23isiMv"
      },
      "source": [
        "print('\\nPreparing the data for LSTM...')\n",
        "\n",
        "# for t, word in enumerate(sentence[:-1]):\n",
        "\n",
        "x_train_2 = np.zeros([len(train_x), 10000], dtype=np.int32)\n",
        "x_test_2 = np.zeros([len(train_x)], dtype=np.int32)\n",
        "for i, sentence in enumerate(train_x):\n",
        "  for t, word in enumerate(sentence.words):\n",
        "    test_x[i, t] = word2index(word)\n",
        "  test_y[i] = word2index(sentence[-1])\n",
        "print('test_x shape:', test_x.shape)\n",
        "print('test_y shape:', test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrSM9x2OeFmG"
      },
      "source": [
        "\n",
        "\n",
        "# Simple run\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[pretrained_weights]))\n",
        "# model.add(Dense(32, activation='relu', input_dim=vocab_size))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train, epochs=2, batch_size=32, verbose=2)"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSMavFTGvayu",
        "outputId": "bd17bcb0-f5ca-484c-f0a6-380380cde3d2"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1070.],\n",
              "       [  23.],\n",
              "       [1702.],\n",
              "       ...,\n",
              "       [1692.],\n",
              "       [2183.],\n",
              "       [ 216.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "pUgPAaIDufol",
        "outputId": "31d661e4-3807-4e5f-d430-f62a4835340f"
      },
      "source": [
        "model.fit(train_x, train_y, epochs=2, batch_size=32, verbose=2)"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-340-0cc31250aef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m-> 3022\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3440\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3441\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3363\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:771 train_step  *\n        loss = self.compiled_loss(\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1742 binary_crossentropy\n        y_true, y_pred, from_logits=from_logits), axis=-1)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4988 binary_crossentropy\n        return tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py:133 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((None, 1000, 200) vs (None, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTDBg82KeggE",
        "outputId": "d9fb8b2f-4e04-46d4-98a7-92481debf87b"
      },
      "source": [
        "# model.fit(train_vecs_w2v, y_train, epochs=2, batch_size=32, verbose=2)\n",
        "score = model.evaluate(test_vecs_w2v, y_test, batch_size=128, verbose=2)\n",
        "print(score[1])\n",
        "# 3/3 - 0s - loss: 0.6508 - accuracy: 0.6567\n",
        "# 0.6567164063453674\n",
        "\n",
        "# 0.7074626684188843\n",
        "\n",
        "# 3/3 - 0s - loss: 0.6148 - accuracy: 0.7194\n",
        "# 0.7194029688835144\n",
        "\n",
        "# 3/3 - 0s - loss: 0.5742 - accuracy: 0.7313\n",
        "# 0.7313432693481445\n",
        "\n",
        "# This was dropping the tf-idf weights\n",
        "# 3/3 - 0s - loss: 0.7349 - accuracy: 0.6239\n",
        "# 0.6238806247711182\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 0.7349 - accuracy: 0.6239\n",
            "0.6238806247711182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XG2ECba95AxE"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2htI39W5AxF"
      },
      "source": [
        "model = Sequential()\n",
        "# model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
        "model.add(Embedding(254, n_dim, input_length=max_review_length)) \n",
        "model.add(SpatialDropout1D(drop_embed))\n",
        "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
        "model.add(MaxPooling1D(mp_size))\n",
        "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgvFYWbx5AxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b04767-9590-4e4a-a9e3-3c540f964636"
      },
      "source": [
        "# LSTM layer parameters double due to both reading directions\n",
        "model.summary() "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1000, 500)         127000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 1000, 500)         0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 998, 64)           96064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 249, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 512)               657408    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 880,985\n",
            "Trainable params: 880,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZObDbC5AxH"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrFj6zDg5AxI"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMMNjK4Z5AxI"
      },
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLcs8GO-5AxJ"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzd1LJrV9R8I",
        "outputId": "a10ac567-bf2f-4185-873d-741542360012"
      },
      "source": [
        "train_x"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 175,   73,  492, ...,    0,    0,    0],\n",
              "       [ 796,  787,   20, ...,    0,    0,    0],\n",
              "       [1107,  375,   53, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 629,  612, 3056, ...,    0,    0,    0],\n",
              "       [ 397,   59, 1230, ...,    0,    0,    0],\n",
              "       [ 439,    0,    0, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o0xTLxn5AxJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "outputId": "0a071eb7-5c4d-49a2-a3a6-c04475a1c666"
      },
      "source": [
        "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[modelcheckpoint])\n",
        "model.fit(train_x, train_y, batch_size=batch_size, epochs=2, verbose=1, validation_data=(test_x, test_y), callbacks=[modelcheckpoint])\n",
        "\n",
        "# model.fit(train_vecs_w2v, y_train, epochs=2, batch_size=32, verbose=2)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 10000).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 10000).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c36293c1b122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[modelcheckpoint])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model.fit(train_vecs_w2v, y_train, epochs=2, batch_size=32, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[9,0] = 1676 is not in [0, 254)\n\t [[node sequential_2/embedding_2/embedding_lookup (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:184) ]]\n\t [[sequential_2/embedding_2/embedding_lookup/_20]]\n  (1) Invalid argument:  indices[9,0] = 1676 is not in [0, 254)\n\t [[node sequential_2/embedding_2/embedding_lookup (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:184) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_10913]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/embedding_2/embedding_lookup:\n sequential_2/embedding_2/Cast (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:183)\t\n sequential_2/embedding_2/embedding_lookup/8495 (defined at /usr/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_2/embedding_2/embedding_lookup:\n sequential_2/embedding_2/Cast (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:183)\t\n sequential_2/embedding_2/embedding_lookup/8495 (defined at /usr/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uzoXTghAoMV5",
        "outputId": "76162114-ef15-465c-c273-8cd54aa88a03"
      },
      "source": [
        "x_train[29].words[0]"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'know'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6krmJw_reRv"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(254, n_dim, input_length=max_review_length)) \n",
        "model.add(SpatialDropout1D(drop_embed))\n",
        "model.add(LSTM(n_lstm, dropout=drop_lstm))\n",
        "# model.add(Dense(n_dense, activation='relu')) \n",
        "# model.add(Dropout(dropout))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWw8wuMerf72"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRRiDKJ1rnfs"
      },
      "source": [
        "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "KScsesVOrqO8",
        "outputId": "31419cbd-7aa3-4751-e1e9-6045c64a2c07"
      },
      "source": [
        "# model.fit(train_vecs_w2v, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[modelcheckpoint])\n",
        "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(test_x, test_y), callbacks=[modelcheckpoint])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 10000).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1000), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 10000).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-f29ad7e0b49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.fit(train_vecs_w2v, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[modelcheckpoint])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[74,0] = 302 is not in [0, 254)\n\t [[node sequential_3/embedding_3/embedding_lookup (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:184) ]]\n\t [[sequential_3/embedding_3/embedding_lookup/_20]]\n  (1) Invalid argument:  indices[74,0] = 302 is not in [0, 254)\n\t [[node sequential_3/embedding_3/embedding_lookup (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:184) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_14279]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_3/embedding_3/embedding_lookup:\n sequential_3/embedding_3/Cast (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:183)\t\n sequential_3/embedding_3/embedding_lookup/12953 (defined at /usr/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_3/embedding_3/embedding_lookup:\n sequential_3/embedding_3/Cast (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/embeddings.py:183)\t\n sequential_3/embedding_3/embedding_lookup/12953 (defined at /usr/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1lSq4oTsLuA"
      },
      "source": [
        "score = model.evaluate(test_vecs_w2v, y_test, batch_size=128, verbose=2)\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bA924lIs5AxL"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omoa9xkw5AxM"
      },
      "source": [
        "model.load_weights(output_dir+\"/weights.02.hdf5\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dl3_BFt5AxN"
      },
      "source": [
        "y_hat = model.predict_proba(x_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77r9sEAd5AxN",
        "outputId": "de95cd86-87b5-466f-ee22-dae8fa87b891"
      },
      "source": [
        "plt.hist(y_hat)\n",
        "_ = plt.axvline(x=0.5, color='orange')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3001f91198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9zlkhu45AxP",
        "outputId": "67b5b33d-be60-4093-eb91-4954daa3a085"
      },
      "source": [
        "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'94.46'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMWudLpl5AxR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}